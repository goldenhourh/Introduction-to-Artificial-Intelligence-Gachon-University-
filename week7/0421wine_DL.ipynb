{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f46e0358-1c9a-450a-83ff-b88f353f83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "168f311a-4bfe-4174-8015-8dfc660cf8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/program1/class/winequality-red.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5acd779-a932-4437-911e-78cd0a31ad6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "064b7f6b-4da9-4be4-8bbb-769864b2fc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        2  \n",
       "1         9.8        2  \n",
       "2         9.8        2  \n",
       "3         9.8        3  \n",
       "4         9.4        2  \n",
       "...       ...      ...  \n",
       "1594     10.5        2  \n",
       "1595     11.2        3  \n",
       "1596     11.0        3  \n",
       "1597     10.2        2  \n",
       "1598     11.0        3  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#레이블을 숫자로 변환\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label = LabelEncoder()\n",
    "\n",
    "# 'class' 열의 데이터에 대해 LabelEncoder를 적용하여 변환\n",
    "df['quality'] = label.fit_transform(df['quality'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "536fd0a7-2526-46b6-a1e4-988d5ab5085e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  citric acid  density  sulphates  alcohol\n",
       "0            7.4         0.00   0.9978       0.56      9.4\n",
       "1            7.8         0.00   0.9968       0.68      9.8\n",
       "2            7.8         0.04   0.9970       0.65      9.8\n",
       "3           11.2         0.56   0.9980       0.58      9.8\n",
       "4            7.4         0.00   0.9978       0.56      9.4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(['volatile acidity', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'quality'], axis=1)\n",
    "# class 컬럼 삭제하여 X에 저장, axis=1 이면 y축 기준\n",
    "X.head()\n",
    "# head()는 첫 5행만 출력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecdd5568-7ab5-4a6e-b241-2f83b4a4f743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    681\n",
       "3    638\n",
       "4    199\n",
       "1     53\n",
       "5     18\n",
       "0     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['quality']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9852dc89-3760-4b79-984b-1ca5d2906ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>9.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.99910</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>9.9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.99710</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99240</td>\n",
       "      <td>0.82</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.99655</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.99738</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.99655</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.99677</td>\n",
       "      <td>0.69</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00210</td>\n",
       "      <td>0.68</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  citric acid  density  sulphates  alcohol\n",
       "642             9.9         0.45  0.99910       0.62      9.4\n",
       "679            10.8         0.45  0.99720       0.54      9.6\n",
       "473             9.9         0.55  0.99710       0.79     10.6\n",
       "390             5.6         0.05  0.99240       0.82     12.9\n",
       "1096            6.6         0.09  0.99655       0.49     10.8\n",
       "...             ...          ...      ...        ...      ...\n",
       "763             9.3         0.26  0.99738       0.42      9.6\n",
       "835             7.6         0.10  0.99655       0.51      9.3\n",
       "1216            7.9         0.31  0.99677       0.69      9.5\n",
       "559            13.0         0.49  1.00210       0.68     12.7\n",
       "684             9.8         0.32  0.99800       0.48      9.4\n",
       "\n",
       "[1279 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# random_state는 데이터를 무작위로 나누거나 섞을 때 사용되는 난수 발생기의 시드(seed) 값\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25c59f95-7cc9-4ae0-95d8-39958dd809a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding \n",
    "\n",
    "y = pd.get_dummies(y).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c7e0b4b-03d3-4274-a5bf-0c708bb74b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.99718</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.99738</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.99655</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.99677</td>\n",
       "      <td>0.69</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00210</td>\n",
       "      <td>0.68</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  citric acid  density  sulphates  alcohol\n",
       "140             8.4         0.11  0.99650       0.82      9.6\n",
       "1232            7.6         0.29  0.99718       0.64      9.5\n",
       "720             8.4         0.04  0.99760       0.44      9.6\n",
       "77              6.8         0.00  0.99660       0.55     10.7\n",
       "39              7.3         0.36  0.99780       0.83     10.5\n",
       "...             ...          ...      ...        ...      ...\n",
       "763             9.3         0.26  0.99738       0.42      9.6\n",
       "835             7.6         0.10  0.99655       0.51      9.3\n",
       "1216            7.9         0.31  0.99677       0.69      9.5\n",
       "559            13.0         0.49  1.00210       0.68     12.7\n",
       "684             9.8         0.32  0.99800       0.48      9.4\n",
       "\n",
       "[1199 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "# random_state는 데이터를 무작위로 나누거나 섞을 때 사용되는 난수 발생기의 시드(seed) 값\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4a66b4f-e235-4546-8f96-7fc2c52e5cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.99718</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.99738</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.99655</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.99677</td>\n",
       "      <td>0.69</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00210</td>\n",
       "      <td>0.68</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  citric acid  density  sulphates  alcohol\n",
       "140             8.4         0.11  0.99650       0.82      9.6\n",
       "1232            7.6         0.29  0.99718       0.64      9.5\n",
       "720             8.4         0.04  0.99760       0.44      9.6\n",
       "77              6.8         0.00  0.99660       0.55     10.7\n",
       "39              7.3         0.36  0.99780       0.83     10.5\n",
       "...             ...          ...      ...        ...      ...\n",
       "763             9.3         0.26  0.99738       0.42      9.6\n",
       "835             7.6         0.10  0.99655       0.51      9.3\n",
       "1216            7.9         0.31  0.99677       0.69      9.5\n",
       "559            13.0         0.49  1.00210       0.68     12.7\n",
       "684             9.8         0.32  0.99800       0.48      9.4\n",
       "\n",
       "[1199 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "# random_state는 데이터를 무작위로 나누거나 섞을 때 사용되는 난수 발생기의 시드(seed) 값\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c8cfdd9-2985-4ca5-b20d-02b4eb898c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 15)                90        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 128       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the model \n",
    "#분류 예제\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15,input_shape=(X_train.shape[1],),activation='tanh'))\n",
    "#input_shape: 입력 데이터의 모양을 지정한다. 첫 번째 레이어에서만 사용된다.\n",
    "model.add(Dense(8,activation='tanh'))\n",
    "#model.add(Dense(8,activation='tanh'))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "#출력 유닛 수는 클래스 수(레이블 수)와 동일하게 설정한다!!!!!!\n",
    "\n",
    "model.compile(Nadam(learning_rate=0.01),'categorical_crossentropy', metrics=['accuracy'])\n",
    "# 이진 분류일 때, model.compile(Adam(lr=0.04),'bce',metrics=['accuracy']) 를 써야한다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19571f69-dc2a-4bb5-8c55-91b2b879ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 1.3902 - accuracy: 0.3428 - val_loss: 1.1526 - val_accuracy: 0.4700\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1950 - accuracy: 0.4412 - val_loss: 1.1510 - val_accuracy: 0.4950\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1836 - accuracy: 0.4754 - val_loss: 1.1409 - val_accuracy: 0.5100\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1678 - accuracy: 0.4779 - val_loss: 1.1710 - val_accuracy: 0.4275\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1613 - accuracy: 0.4821 - val_loss: 1.1139 - val_accuracy: 0.4825\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1355 - accuracy: 0.4954 - val_loss: 1.0750 - val_accuracy: 0.4975\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1181 - accuracy: 0.4987 - val_loss: 1.0665 - val_accuracy: 0.4950\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1053 - accuracy: 0.4879 - val_loss: 1.0650 - val_accuracy: 0.4875\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0994 - accuracy: 0.5013 - val_loss: 1.0482 - val_accuracy: 0.5150\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0839 - accuracy: 0.5179 - val_loss: 1.0563 - val_accuracy: 0.5650\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0901 - accuracy: 0.4912 - val_loss: 1.0317 - val_accuracy: 0.5475\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0765 - accuracy: 0.5263 - val_loss: 1.0337 - val_accuracy: 0.5775\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.5288 - val_loss: 1.0223 - val_accuracy: 0.5225\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0741 - accuracy: 0.5138 - val_loss: 1.1444 - val_accuracy: 0.4725\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0534 - accuracy: 0.5246 - val_loss: 1.0385 - val_accuracy: 0.5650\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.5413 - val_loss: 1.0113 - val_accuracy: 0.5275\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5179 - val_loss: 0.9985 - val_accuracy: 0.5850\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.5288 - val_loss: 1.0370 - val_accuracy: 0.5300\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0483 - accuracy: 0.5246 - val_loss: 0.9999 - val_accuracy: 0.5800\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0429 - accuracy: 0.5321 - val_loss: 1.4615 - val_accuracy: 0.2350\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0681 - accuracy: 0.5163 - val_loss: 0.9821 - val_accuracy: 0.5775\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0440 - accuracy: 0.5313 - val_loss: 0.9908 - val_accuracy: 0.5875\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0283 - accuracy: 0.5488 - val_loss: 0.9934 - val_accuracy: 0.5950\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.5346 - val_loss: 1.1656 - val_accuracy: 0.4650\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0452 - accuracy: 0.5455 - val_loss: 0.9847 - val_accuracy: 0.5700\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0279 - accuracy: 0.5379 - val_loss: 0.9818 - val_accuracy: 0.5825\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0335 - accuracy: 0.5371 - val_loss: 1.0340 - val_accuracy: 0.5650\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0279 - accuracy: 0.5513 - val_loss: 0.9726 - val_accuracy: 0.5875\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0274 - accuracy: 0.5430 - val_loss: 0.9707 - val_accuracy: 0.5825\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0313 - accuracy: 0.5513 - val_loss: 0.9721 - val_accuracy: 0.5825\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0138 - accuracy: 0.5596 - val_loss: 0.9663 - val_accuracy: 0.5850\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0308 - accuracy: 0.5304 - val_loss: 1.1998 - val_accuracy: 0.3925\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0261 - accuracy: 0.5396 - val_loss: 1.0302 - val_accuracy: 0.5525\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.5588 - val_loss: 0.9661 - val_accuracy: 0.5825\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0084 - accuracy: 0.5630 - val_loss: 0.9835 - val_accuracy: 0.5725\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0131 - accuracy: 0.5463 - val_loss: 0.9631 - val_accuracy: 0.5750\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0191 - accuracy: 0.5421 - val_loss: 0.9712 - val_accuracy: 0.5700\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0111 - accuracy: 0.5496 - val_loss: 1.2221 - val_accuracy: 0.4750\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.5438 - val_loss: 1.0029 - val_accuracy: 0.5800\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0169 - accuracy: 0.5530 - val_loss: 0.9774 - val_accuracy: 0.6100\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0088 - accuracy: 0.5613 - val_loss: 0.9913 - val_accuracy: 0.5550\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0013 - accuracy: 0.5588 - val_loss: 0.9619 - val_accuracy: 0.5900\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0195 - accuracy: 0.5338 - val_loss: 0.9610 - val_accuracy: 0.5850\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5538 - val_loss: 0.9815 - val_accuracy: 0.5850\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.5538 - val_loss: 0.9550 - val_accuracy: 0.5900\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9996 - accuracy: 0.5555 - val_loss: 0.9696 - val_accuracy: 0.5950\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0171 - accuracy: 0.5513 - val_loss: 0.9524 - val_accuracy: 0.6125\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.5455 - val_loss: 0.9615 - val_accuracy: 0.6150\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0053 - accuracy: 0.5505 - val_loss: 1.0701 - val_accuracy: 0.5150\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.5605 - val_loss: 0.9613 - val_accuracy: 0.5875\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.5521 - val_loss: 1.0077 - val_accuracy: 0.5575\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9958 - accuracy: 0.5730 - val_loss: 0.9511 - val_accuracy: 0.5750\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0016 - accuracy: 0.5546 - val_loss: 0.9748 - val_accuracy: 0.5775\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9945 - accuracy: 0.5605 - val_loss: 1.0189 - val_accuracy: 0.5450\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9861 - accuracy: 0.5663 - val_loss: 1.1831 - val_accuracy: 0.4775\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0072 - accuracy: 0.5555 - val_loss: 0.9491 - val_accuracy: 0.6250\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.5696 - val_loss: 0.9654 - val_accuracy: 0.5850\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.5671 - val_loss: 1.0268 - val_accuracy: 0.5600\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9988 - accuracy: 0.5571 - val_loss: 0.9601 - val_accuracy: 0.5725\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9828 - accuracy: 0.5555 - val_loss: 0.9552 - val_accuracy: 0.5925\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9914 - accuracy: 0.5538 - val_loss: 0.9453 - val_accuracy: 0.5800\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0036 - accuracy: 0.5480 - val_loss: 0.9698 - val_accuracy: 0.5825\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9918 - accuracy: 0.5613 - val_loss: 1.0885 - val_accuracy: 0.5100\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.5638 - val_loss: 0.9471 - val_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5680 - val_loss: 0.9533 - val_accuracy: 0.5625\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9849 - accuracy: 0.5738 - val_loss: 0.9561 - val_accuracy: 0.5975\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.5480 - val_loss: 1.0356 - val_accuracy: 0.5100\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9868 - accuracy: 0.5763 - val_loss: 0.9421 - val_accuracy: 0.5975\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9874 - accuracy: 0.5705 - val_loss: 0.9761 - val_accuracy: 0.5850\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9825 - accuracy: 0.5630 - val_loss: 0.9518 - val_accuracy: 0.5725\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9961 - accuracy: 0.5571 - val_loss: 0.9598 - val_accuracy: 0.5875\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9775 - accuracy: 0.5571 - val_loss: 0.9646 - val_accuracy: 0.5775\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9805 - accuracy: 0.5630 - val_loss: 0.9364 - val_accuracy: 0.6100\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9768 - accuracy: 0.5730 - val_loss: 0.9672 - val_accuracy: 0.5725\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9890 - accuracy: 0.5746 - val_loss: 0.9540 - val_accuracy: 0.5725\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9805 - accuracy: 0.5571 - val_loss: 0.9423 - val_accuracy: 0.6075\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9832 - accuracy: 0.5688 - val_loss: 0.9930 - val_accuracy: 0.5750\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9777 - accuracy: 0.5563 - val_loss: 0.9598 - val_accuracy: 0.5700\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9840 - accuracy: 0.5705 - val_loss: 1.0013 - val_accuracy: 0.5250\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5746 - val_loss: 1.0445 - val_accuracy: 0.5000\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9826 - accuracy: 0.5663 - val_loss: 0.9603 - val_accuracy: 0.5600\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9836 - accuracy: 0.5621 - val_loss: 0.9465 - val_accuracy: 0.6025\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.5746 - val_loss: 0.9334 - val_accuracy: 0.5950\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9698 - accuracy: 0.5813 - val_loss: 0.9910 - val_accuracy: 0.5425\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.5763 - val_loss: 0.9419 - val_accuracy: 0.6075\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9787 - accuracy: 0.5763 - val_loss: 0.9464 - val_accuracy: 0.5725\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.5771 - val_loss: 0.9467 - val_accuracy: 0.5975\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9727 - accuracy: 0.5605 - val_loss: 1.0115 - val_accuracy: 0.5400\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9684 - accuracy: 0.5780 - val_loss: 0.9515 - val_accuracy: 0.5675\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9762 - accuracy: 0.5613 - val_loss: 0.9457 - val_accuracy: 0.5850\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9726 - accuracy: 0.5646 - val_loss: 0.9370 - val_accuracy: 0.5875\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.5763 - val_loss: 0.9485 - val_accuracy: 0.5925\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9681 - accuracy: 0.5721 - val_loss: 0.9673 - val_accuracy: 0.5575\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9711 - accuracy: 0.5746 - val_loss: 1.0992 - val_accuracy: 0.4900\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.5746 - val_loss: 0.9598 - val_accuracy: 0.5950\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9783 - accuracy: 0.5780 - val_loss: 0.9416 - val_accuracy: 0.5900\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.5646 - val_loss: 0.9432 - val_accuracy: 0.5950\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9732 - accuracy: 0.5621 - val_loss: 0.9435 - val_accuracy: 0.5875\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9657 - accuracy: 0.5746 - val_loss: 0.9683 - val_accuracy: 0.5725\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9725 - accuracy: 0.5663 - val_loss: 0.9438 - val_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9648 - accuracy: 0.5688 - val_loss: 0.9496 - val_accuracy: 0.6025\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5655 - val_loss: 0.9493 - val_accuracy: 0.5675\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.5755 - val_loss: 0.9468 - val_accuracy: 0.5825\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9714 - accuracy: 0.5646 - val_loss: 0.9387 - val_accuracy: 0.5875\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9653 - accuracy: 0.5696 - val_loss: 0.9898 - val_accuracy: 0.5600\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9684 - accuracy: 0.5655 - val_loss: 0.9413 - val_accuracy: 0.5900\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9642 - accuracy: 0.5771 - val_loss: 0.9526 - val_accuracy: 0.5825\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.5671 - val_loss: 0.9357 - val_accuracy: 0.6025\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.5796 - val_loss: 0.9508 - val_accuracy: 0.6075\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9698 - accuracy: 0.5638 - val_loss: 0.9792 - val_accuracy: 0.5600\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9696 - accuracy: 0.5713 - val_loss: 0.9549 - val_accuracy: 0.5775\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9716 - accuracy: 0.5755 - val_loss: 0.9449 - val_accuracy: 0.5875\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9626 - accuracy: 0.5638 - val_loss: 0.9620 - val_accuracy: 0.5575\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9590 - accuracy: 0.5847 - val_loss: 0.9699 - val_accuracy: 0.5800\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9663 - accuracy: 0.5688 - val_loss: 0.9672 - val_accuracy: 0.5750\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.5771 - val_loss: 0.9573 - val_accuracy: 0.5550\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9664 - accuracy: 0.5738 - val_loss: 0.9448 - val_accuracy: 0.5925\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9607 - accuracy: 0.5646 - val_loss: 0.9479 - val_accuracy: 0.5950\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.5796 - val_loss: 0.9658 - val_accuracy: 0.5525\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9614 - accuracy: 0.5688 - val_loss: 0.9465 - val_accuracy: 0.5825\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9701 - accuracy: 0.5721 - val_loss: 1.0093 - val_accuracy: 0.5300\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9593 - accuracy: 0.5805 - val_loss: 0.9524 - val_accuracy: 0.5875\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9643 - accuracy: 0.5822 - val_loss: 1.0128 - val_accuracy: 0.5450\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.5705 - val_loss: 0.9432 - val_accuracy: 0.5875\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9593 - accuracy: 0.5755 - val_loss: 0.9661 - val_accuracy: 0.6025\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9630 - accuracy: 0.5721 - val_loss: 0.9530 - val_accuracy: 0.5700\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.5671 - val_loss: 0.9555 - val_accuracy: 0.6025\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.5763 - val_loss: 0.9501 - val_accuracy: 0.5825\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.5671 - val_loss: 1.0601 - val_accuracy: 0.5750\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5763 - val_loss: 0.9412 - val_accuracy: 0.6100\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.5930 - val_loss: 0.9440 - val_accuracy: 0.5850\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9617 - accuracy: 0.5796 - val_loss: 1.0419 - val_accuracy: 0.5225\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9574 - accuracy: 0.5897 - val_loss: 0.9488 - val_accuracy: 0.6175\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.5730 - val_loss: 0.9543 - val_accuracy: 0.5625\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9593 - accuracy: 0.5721 - val_loss: 1.0076 - val_accuracy: 0.5500\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.5721 - val_loss: 0.9508 - val_accuracy: 0.5725\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9556 - accuracy: 0.5738 - val_loss: 0.9500 - val_accuracy: 0.6125\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9564 - accuracy: 0.5830 - val_loss: 0.9473 - val_accuracy: 0.6025\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9598 - accuracy: 0.5755 - val_loss: 0.9385 - val_accuracy: 0.6100\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.5688 - val_loss: 0.9489 - val_accuracy: 0.5875\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.5730 - val_loss: 0.9675 - val_accuracy: 0.6025\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9607 - accuracy: 0.5663 - val_loss: 0.9529 - val_accuracy: 0.6075\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9553 - accuracy: 0.5721 - val_loss: 0.9522 - val_accuracy: 0.5725\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9572 - accuracy: 0.5663 - val_loss: 0.9750 - val_accuracy: 0.5525\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9496 - accuracy: 0.5855 - val_loss: 0.9661 - val_accuracy: 0.5350\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9598 - accuracy: 0.5746 - val_loss: 0.9593 - val_accuracy: 0.5500\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9628 - accuracy: 0.5705 - val_loss: 0.9953 - val_accuracy: 0.5450\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.5755 - val_loss: 0.9615 - val_accuracy: 0.5975\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9574 - accuracy: 0.5788 - val_loss: 0.9556 - val_accuracy: 0.6050\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5680 - val_loss: 0.9854 - val_accuracy: 0.5300\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9533 - accuracy: 0.5746 - val_loss: 0.9663 - val_accuracy: 0.5650\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9523 - accuracy: 0.5880 - val_loss: 0.9434 - val_accuracy: 0.6000\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.5721 - val_loss: 0.9582 - val_accuracy: 0.6025\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.5730 - val_loss: 0.9513 - val_accuracy: 0.6200\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5621 - val_loss: 0.9552 - val_accuracy: 0.5875\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9527 - accuracy: 0.5805 - val_loss: 0.9694 - val_accuracy: 0.5650\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9533 - accuracy: 0.5763 - val_loss: 0.9409 - val_accuracy: 0.6050\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9503 - accuracy: 0.5872 - val_loss: 1.0014 - val_accuracy: 0.6025\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9534 - accuracy: 0.5855 - val_loss: 0.9654 - val_accuracy: 0.5575\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9516 - accuracy: 0.5738 - val_loss: 0.9548 - val_accuracy: 0.5675\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9480 - accuracy: 0.5838 - val_loss: 0.9608 - val_accuracy: 0.5925\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9498 - accuracy: 0.5838 - val_loss: 0.9895 - val_accuracy: 0.5450\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9519 - accuracy: 0.5671 - val_loss: 0.9479 - val_accuracy: 0.6075\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9451 - accuracy: 0.5705 - val_loss: 1.0277 - val_accuracy: 0.5200\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9662 - accuracy: 0.5730 - val_loss: 0.9421 - val_accuracy: 0.5875\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9450 - accuracy: 0.5638 - val_loss: 0.9568 - val_accuracy: 0.5925\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.5838 - val_loss: 0.9550 - val_accuracy: 0.6150\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9526 - accuracy: 0.5763 - val_loss: 0.9501 - val_accuracy: 0.5975\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9440 - accuracy: 0.5888 - val_loss: 0.9484 - val_accuracy: 0.5925\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9488 - accuracy: 0.5663 - val_loss: 1.0218 - val_accuracy: 0.5075\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.5771 - val_loss: 0.9500 - val_accuracy: 0.5800\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9511 - accuracy: 0.5788 - val_loss: 0.9634 - val_accuracy: 0.5875\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9490 - accuracy: 0.5763 - val_loss: 0.9448 - val_accuracy: 0.6150\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9505 - accuracy: 0.5813 - val_loss: 0.9956 - val_accuracy: 0.5675\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9513 - accuracy: 0.5805 - val_loss: 0.9558 - val_accuracy: 0.6075\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.5788 - val_loss: 0.9529 - val_accuracy: 0.5825\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.5730 - val_loss: 1.0628 - val_accuracy: 0.4950\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9500 - accuracy: 0.5847 - val_loss: 0.9494 - val_accuracy: 0.5925\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9387 - accuracy: 0.5922 - val_loss: 0.9634 - val_accuracy: 0.5950\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5713 - val_loss: 0.9728 - val_accuracy: 0.5625\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.5880 - val_loss: 0.9815 - val_accuracy: 0.5650\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9480 - accuracy: 0.5847 - val_loss: 0.9854 - val_accuracy: 0.5500\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.5822 - val_loss: 0.9696 - val_accuracy: 0.5525\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9448 - accuracy: 0.5855 - val_loss: 0.9525 - val_accuracy: 0.5925\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.5721 - val_loss: 0.9538 - val_accuracy: 0.6050\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9443 - accuracy: 0.5813 - val_loss: 0.9686 - val_accuracy: 0.6250\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9423 - accuracy: 0.5805 - val_loss: 0.9764 - val_accuracy: 0.5450\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.5771 - val_loss: 0.9801 - val_accuracy: 0.5600\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9451 - accuracy: 0.5755 - val_loss: 0.9724 - val_accuracy: 0.6050\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.5963 - val_loss: 0.9796 - val_accuracy: 0.5275\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9421 - accuracy: 0.5713 - val_loss: 0.9639 - val_accuracy: 0.5700\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9438 - accuracy: 0.5796 - val_loss: 0.9960 - val_accuracy: 0.5675\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9425 - accuracy: 0.5872 - val_loss: 0.9717 - val_accuracy: 0.5700\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9401 - accuracy: 0.5822 - val_loss: 0.9916 - val_accuracy: 0.6150\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9474 - accuracy: 0.5780 - val_loss: 0.9872 - val_accuracy: 0.5425\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9486 - accuracy: 0.5763 - val_loss: 1.0479 - val_accuracy: 0.5225\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.5930 - val_loss: 0.9795 - val_accuracy: 0.5550\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9397 - accuracy: 0.5863 - val_loss: 0.9581 - val_accuracy: 0.5825\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9486 - accuracy: 0.5805 - val_loss: 0.9990 - val_accuracy: 0.5400\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9452 - accuracy: 0.5913 - val_loss: 1.0036 - val_accuracy: 0.5425\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9423 - accuracy: 0.5730 - val_loss: 1.0248 - val_accuracy: 0.5325\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.5738 - val_loss: 1.0334 - val_accuracy: 0.5775\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9404 - accuracy: 0.5838 - val_loss: 0.9699 - val_accuracy: 0.5700\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9399 - accuracy: 0.5855 - val_loss: 0.9720 - val_accuracy: 0.5650\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9379 - accuracy: 0.5738 - val_loss: 0.9544 - val_accuracy: 0.6000\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9469 - accuracy: 0.5913 - val_loss: 0.9469 - val_accuracy: 0.6025\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.5780 - val_loss: 0.9600 - val_accuracy: 0.5925\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9406 - accuracy: 0.5830 - val_loss: 0.9734 - val_accuracy: 0.5800\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.5705 - val_loss: 0.9726 - val_accuracy: 0.5800\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9397 - accuracy: 0.5738 - val_loss: 0.9714 - val_accuracy: 0.6000\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9431 - accuracy: 0.5888 - val_loss: 0.9685 - val_accuracy: 0.5700\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9374 - accuracy: 0.5813 - val_loss: 0.9599 - val_accuracy: 0.5950\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9399 - accuracy: 0.5838 - val_loss: 0.9566 - val_accuracy: 0.5975\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9380 - accuracy: 0.5913 - val_loss: 0.9477 - val_accuracy: 0.6150\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9376 - accuracy: 0.5838 - val_loss: 0.9725 - val_accuracy: 0.5500\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9338 - accuracy: 0.5872 - val_loss: 0.9567 - val_accuracy: 0.6125\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9400 - accuracy: 0.5763 - val_loss: 1.0166 - val_accuracy: 0.5275\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9463 - accuracy: 0.5897 - val_loss: 0.9611 - val_accuracy: 0.5850\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9324 - accuracy: 0.5922 - val_loss: 0.9585 - val_accuracy: 0.6100\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9405 - accuracy: 0.5897 - val_loss: 0.9772 - val_accuracy: 0.6050\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9439 - accuracy: 0.5838 - val_loss: 0.9623 - val_accuracy: 0.6125\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9485 - accuracy: 0.5788 - val_loss: 0.9620 - val_accuracy: 0.5850\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9349 - accuracy: 0.5880 - val_loss: 0.9601 - val_accuracy: 0.5850\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.5863 - val_loss: 0.9673 - val_accuracy: 0.5875\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9399 - accuracy: 0.5771 - val_loss: 0.9763 - val_accuracy: 0.6025\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9309 - accuracy: 0.5905 - val_loss: 0.9594 - val_accuracy: 0.5725\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9311 - accuracy: 0.5855 - val_loss: 0.9571 - val_accuracy: 0.6025\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9360 - accuracy: 0.5972 - val_loss: 0.9694 - val_accuracy: 0.6150\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9377 - accuracy: 0.5880 - val_loss: 0.9835 - val_accuracy: 0.6050\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9363 - accuracy: 0.6005 - val_loss: 0.9646 - val_accuracy: 0.5875\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9337 - accuracy: 0.5888 - val_loss: 0.9868 - val_accuracy: 0.5475\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9323 - accuracy: 0.6022 - val_loss: 0.9661 - val_accuracy: 0.5750\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.5863 - val_loss: 0.9676 - val_accuracy: 0.5700\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9319 - accuracy: 0.5963 - val_loss: 0.9732 - val_accuracy: 0.5700\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9343 - accuracy: 0.5830 - val_loss: 0.9560 - val_accuracy: 0.5825\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9339 - accuracy: 0.5822 - val_loss: 1.0300 - val_accuracy: 0.5350\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9317 - accuracy: 0.5788 - val_loss: 0.9690 - val_accuracy: 0.5700\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9348 - accuracy: 0.5938 - val_loss: 0.9810 - val_accuracy: 0.5550\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9320 - accuracy: 0.5913 - val_loss: 0.9583 - val_accuracy: 0.6150\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9285 - accuracy: 0.5980 - val_loss: 0.9750 - val_accuracy: 0.5650\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9317 - accuracy: 0.5972 - val_loss: 0.9534 - val_accuracy: 0.5775\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9353 - accuracy: 0.5847 - val_loss: 0.9668 - val_accuracy: 0.5875\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9354 - accuracy: 0.5938 - val_loss: 0.9651 - val_accuracy: 0.5650\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9308 - accuracy: 0.6030 - val_loss: 0.9828 - val_accuracy: 0.5500\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9372 - accuracy: 0.5822 - val_loss: 0.9565 - val_accuracy: 0.6050\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9385 - accuracy: 0.5988 - val_loss: 0.9969 - val_accuracy: 0.5425\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.5963 - val_loss: 0.9952 - val_accuracy: 0.5525\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9364 - accuracy: 0.5872 - val_loss: 0.9650 - val_accuracy: 0.5850\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9309 - accuracy: 0.5830 - val_loss: 0.9593 - val_accuracy: 0.5975\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9370 - accuracy: 0.5938 - val_loss: 0.9647 - val_accuracy: 0.5700\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9273 - accuracy: 0.6022 - val_loss: 0.9873 - val_accuracy: 0.5550\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9305 - accuracy: 0.5955 - val_loss: 0.9727 - val_accuracy: 0.5600\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.5997 - val_loss: 0.9659 - val_accuracy: 0.5600\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9304 - accuracy: 0.5888 - val_loss: 0.9683 - val_accuracy: 0.5875\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9285 - accuracy: 0.5813 - val_loss: 0.9678 - val_accuracy: 0.5725\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9311 - accuracy: 0.5872 - val_loss: 0.9615 - val_accuracy: 0.5975\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9307 - accuracy: 0.5771 - val_loss: 0.9487 - val_accuracy: 0.6200\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.5755 - val_loss: 0.9520 - val_accuracy: 0.6225\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9306 - accuracy: 0.5905 - val_loss: 0.9661 - val_accuracy: 0.5950\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.5796 - val_loss: 0.9980 - val_accuracy: 0.5600\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9339 - accuracy: 0.5938 - val_loss: 0.9629 - val_accuracy: 0.5900\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9300 - accuracy: 0.5872 - val_loss: 0.9722 - val_accuracy: 0.6000\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9367 - accuracy: 0.5872 - val_loss: 0.9732 - val_accuracy: 0.5825\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9341 - accuracy: 0.5888 - val_loss: 0.9992 - val_accuracy: 0.5675\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9368 - accuracy: 0.5847 - val_loss: 0.9637 - val_accuracy: 0.6025\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9321 - accuracy: 0.5863 - val_loss: 0.9645 - val_accuracy: 0.5700\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9259 - accuracy: 0.6005 - val_loss: 0.9738 - val_accuracy: 0.5950\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9332 - accuracy: 0.5938 - val_loss: 0.9631 - val_accuracy: 0.5975\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9275 - accuracy: 0.5963 - val_loss: 0.9657 - val_accuracy: 0.5975\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9286 - accuracy: 0.5855 - val_loss: 0.9858 - val_accuracy: 0.5575\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9310 - accuracy: 0.5930 - val_loss: 0.9777 - val_accuracy: 0.5575\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9283 - accuracy: 0.5830 - val_loss: 0.9784 - val_accuracy: 0.5825\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9300 - accuracy: 0.5863 - val_loss: 0.9673 - val_accuracy: 0.6025\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9238 - accuracy: 0.5922 - val_loss: 1.0109 - val_accuracy: 0.5950\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9324 - accuracy: 0.5905 - val_loss: 0.9781 - val_accuracy: 0.5675\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9303 - accuracy: 0.5838 - val_loss: 0.9868 - val_accuracy: 0.5800\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9314 - accuracy: 0.6047 - val_loss: 0.9599 - val_accuracy: 0.6000\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9288 - accuracy: 0.5913 - val_loss: 0.9705 - val_accuracy: 0.5775\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5930 - val_loss: 0.9907 - val_accuracy: 0.5750\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9304 - accuracy: 0.5880 - val_loss: 1.0237 - val_accuracy: 0.5825\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9256 - accuracy: 0.5988 - val_loss: 0.9889 - val_accuracy: 0.6200\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5947 - val_loss: 0.9672 - val_accuracy: 0.5850\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9210 - accuracy: 0.6022 - val_loss: 0.9800 - val_accuracy: 0.5800\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.5805 - val_loss: 0.9736 - val_accuracy: 0.5725\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.5922 - val_loss: 0.9944 - val_accuracy: 0.5425\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.5788 - val_loss: 0.9713 - val_accuracy: 0.5750\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9260 - accuracy: 0.5947 - val_loss: 0.9655 - val_accuracy: 0.5875\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9307 - accuracy: 0.5997 - val_loss: 0.9903 - val_accuracy: 0.6025\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9338 - accuracy: 0.5955 - val_loss: 0.9572 - val_accuracy: 0.5800\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9336 - accuracy: 0.5930 - val_loss: 0.9575 - val_accuracy: 0.6025\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9209 - accuracy: 0.5947 - val_loss: 0.9742 - val_accuracy: 0.6100\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9254 - accuracy: 0.5997 - val_loss: 0.9930 - val_accuracy: 0.5475\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9273 - accuracy: 0.5913 - val_loss: 0.9969 - val_accuracy: 0.5550\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9328 - accuracy: 0.5955 - val_loss: 0.9638 - val_accuracy: 0.5900\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9328 - accuracy: 0.5671 - val_loss: 0.9621 - val_accuracy: 0.6150\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9239 - accuracy: 0.5922 - val_loss: 0.9753 - val_accuracy: 0.6125\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.5963 - val_loss: 0.9702 - val_accuracy: 0.6025\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9258 - accuracy: 0.6072 - val_loss: 1.0039 - val_accuracy: 0.5600\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9300 - accuracy: 0.5880 - val_loss: 0.9727 - val_accuracy: 0.5875\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9247 - accuracy: 0.5972 - val_loss: 0.9800 - val_accuracy: 0.5700\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9286 - accuracy: 0.5897 - val_loss: 0.9914 - val_accuracy: 0.5575\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9219 - accuracy: 0.5913 - val_loss: 0.9676 - val_accuracy: 0.5950\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.5997 - val_loss: 0.9659 - val_accuracy: 0.5975\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9250 - accuracy: 0.5888 - val_loss: 0.9781 - val_accuracy: 0.5775\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9255 - accuracy: 0.5988 - val_loss: 0.9562 - val_accuracy: 0.6100\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9221 - accuracy: 0.5972 - val_loss: 0.9782 - val_accuracy: 0.5575\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9265 - accuracy: 0.6013 - val_loss: 0.9816 - val_accuracy: 0.5775\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9204 - accuracy: 0.6055 - val_loss: 1.0070 - val_accuracy: 0.5600\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9254 - accuracy: 0.5938 - val_loss: 0.9742 - val_accuracy: 0.5875\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9264 - accuracy: 0.5872 - val_loss: 0.9565 - val_accuracy: 0.6075\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9216 - accuracy: 0.5855 - val_loss: 0.9995 - val_accuracy: 0.5700\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9196 - accuracy: 0.5980 - val_loss: 0.9590 - val_accuracy: 0.5800\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9216 - accuracy: 0.5863 - val_loss: 0.9786 - val_accuracy: 0.5800\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9319 - accuracy: 0.5938 - val_loss: 0.9748 - val_accuracy: 0.5775\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.5872 - val_loss: 0.9580 - val_accuracy: 0.6100\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9245 - accuracy: 0.5972 - val_loss: 0.9964 - val_accuracy: 0.5550\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9183 - accuracy: 0.6022 - val_loss: 1.0459 - val_accuracy: 0.5325\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9344 - accuracy: 0.5897 - val_loss: 1.0023 - val_accuracy: 0.5325\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9286 - accuracy: 0.5955 - val_loss: 0.9864 - val_accuracy: 0.5825\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9299 - accuracy: 0.5938 - val_loss: 0.9874 - val_accuracy: 0.5825\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9226 - accuracy: 0.5822 - val_loss: 0.9632 - val_accuracy: 0.5975\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9210 - accuracy: 0.6072 - val_loss: 1.0207 - val_accuracy: 0.5425\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9322 - accuracy: 0.5897 - val_loss: 0.9783 - val_accuracy: 0.5650\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9205 - accuracy: 0.5863 - val_loss: 0.9620 - val_accuracy: 0.5875\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.5913 - val_loss: 0.9975 - val_accuracy: 0.5725\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9244 - accuracy: 0.5955 - val_loss: 1.0069 - val_accuracy: 0.5550\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.6105 - val_loss: 0.9742 - val_accuracy: 0.5625\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9276 - accuracy: 0.6005 - val_loss: 0.9973 - val_accuracy: 0.5650\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.5905 - val_loss: 0.9700 - val_accuracy: 0.5675\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9237 - accuracy: 0.6005 - val_loss: 0.9742 - val_accuracy: 0.5875\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.5988 - val_loss: 0.9639 - val_accuracy: 0.5925\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.5963 - val_loss: 0.9768 - val_accuracy: 0.5800\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.5947 - val_loss: 0.9743 - val_accuracy: 0.5925\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9234 - accuracy: 0.5863 - val_loss: 0.9608 - val_accuracy: 0.5725\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9152 - accuracy: 0.6055 - val_loss: 0.9746 - val_accuracy: 0.5725\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9185 - accuracy: 0.5822 - val_loss: 0.9698 - val_accuracy: 0.5875\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.5955 - val_loss: 0.9647 - val_accuracy: 0.5950\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9196 - accuracy: 0.5913 - val_loss: 0.9745 - val_accuracy: 0.5625\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9191 - accuracy: 0.6022 - val_loss: 0.9925 - val_accuracy: 0.5800\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9259 - accuracy: 0.5963 - val_loss: 0.9752 - val_accuracy: 0.6000\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9213 - accuracy: 0.5880 - val_loss: 1.0167 - val_accuracy: 0.5500\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.5888 - val_loss: 0.9679 - val_accuracy: 0.5900\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9238 - accuracy: 0.5897 - val_loss: 0.9686 - val_accuracy: 0.5950\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.5972 - val_loss: 0.9576 - val_accuracy: 0.6050\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9215 - accuracy: 0.5863 - val_loss: 0.9641 - val_accuracy: 0.5850\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9207 - accuracy: 0.5922 - val_loss: 0.9672 - val_accuracy: 0.6025\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9232 - accuracy: 0.5980 - val_loss: 0.9873 - val_accuracy: 0.5500\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9203 - accuracy: 0.5955 - val_loss: 0.9554 - val_accuracy: 0.6225\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9224 - accuracy: 0.5897 - val_loss: 0.9551 - val_accuracy: 0.6150\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5905 - val_loss: 0.9737 - val_accuracy: 0.6050\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9199 - accuracy: 0.5922 - val_loss: 0.9800 - val_accuracy: 0.5675\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9154 - accuracy: 0.5922 - val_loss: 1.0249 - val_accuracy: 0.5325\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.5930 - val_loss: 0.9851 - val_accuracy: 0.5675\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9233 - accuracy: 0.5938 - val_loss: 0.9790 - val_accuracy: 0.5875\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9272 - accuracy: 0.5863 - val_loss: 1.0000 - val_accuracy: 0.5800\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9229 - accuracy: 0.5988 - val_loss: 0.9652 - val_accuracy: 0.5750\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9196 - accuracy: 0.5988 - val_loss: 0.9774 - val_accuracy: 0.5650\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9226 - accuracy: 0.5963 - val_loss: 0.9621 - val_accuracy: 0.6150\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.6013 - val_loss: 0.9728 - val_accuracy: 0.5925\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.6022 - val_loss: 1.0036 - val_accuracy: 0.5500\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9232 - accuracy: 0.5897 - val_loss: 0.9822 - val_accuracy: 0.5850\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9163 - accuracy: 0.5930 - val_loss: 0.9736 - val_accuracy: 0.5775\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9156 - accuracy: 0.6005 - val_loss: 0.9685 - val_accuracy: 0.6100\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9266 - accuracy: 0.5997 - val_loss: 0.9558 - val_accuracy: 0.6050\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9174 - accuracy: 0.5938 - val_loss: 0.9929 - val_accuracy: 0.5700\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9155 - accuracy: 0.5997 - val_loss: 0.9794 - val_accuracy: 0.6050\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9160 - accuracy: 0.5888 - val_loss: 0.9657 - val_accuracy: 0.6000\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9223 - accuracy: 0.5955 - val_loss: 0.9674 - val_accuracy: 0.5900\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9146 - accuracy: 0.6013 - val_loss: 0.9800 - val_accuracy: 0.5775\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9203 - accuracy: 0.6005 - val_loss: 1.0171 - val_accuracy: 0.6075\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.5997 - val_loss: 0.9929 - val_accuracy: 0.5900\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9204 - accuracy: 0.5922 - val_loss: 1.0031 - val_accuracy: 0.5425\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9261 - accuracy: 0.5922 - val_loss: 1.0004 - val_accuracy: 0.5575\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9197 - accuracy: 0.5930 - val_loss: 0.9960 - val_accuracy: 0.5475\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9098 - accuracy: 0.5988 - val_loss: 0.9931 - val_accuracy: 0.5525\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9209 - accuracy: 0.5947 - val_loss: 1.0079 - val_accuracy: 0.5575\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.6005 - val_loss: 0.9859 - val_accuracy: 0.5800\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9137 - accuracy: 0.5972 - val_loss: 0.9675 - val_accuracy: 0.6000\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9120 - accuracy: 0.6047 - val_loss: 0.9914 - val_accuracy: 0.5550\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.5955 - val_loss: 0.9790 - val_accuracy: 0.5800\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9216 - accuracy: 0.5930 - val_loss: 0.9752 - val_accuracy: 0.5700\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.5922 - val_loss: 1.0088 - val_accuracy: 0.5625\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9207 - accuracy: 0.5988 - val_loss: 1.0093 - val_accuracy: 0.5525\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.5805 - val_loss: 0.9656 - val_accuracy: 0.6075\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9178 - accuracy: 0.5947 - val_loss: 1.0080 - val_accuracy: 0.5575\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.5872 - val_loss: 0.9774 - val_accuracy: 0.5800\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.5847 - val_loss: 0.9794 - val_accuracy: 0.5975\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.5997 - val_loss: 0.9594 - val_accuracy: 0.6175\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9155 - accuracy: 0.6005 - val_loss: 1.0051 - val_accuracy: 0.5550\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9264 - accuracy: 0.5880 - val_loss: 0.9842 - val_accuracy: 0.5725\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9228 - accuracy: 0.6005 - val_loss: 0.9684 - val_accuracy: 0.5975\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9181 - accuracy: 0.5963 - val_loss: 1.0223 - val_accuracy: 0.5300\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9243 - accuracy: 0.5988 - val_loss: 0.9595 - val_accuracy: 0.6075\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.5972 - val_loss: 0.9744 - val_accuracy: 0.5800\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.6022 - val_loss: 0.9848 - val_accuracy: 0.5675\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.5947 - val_loss: 0.9692 - val_accuracy: 0.5875\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5963 - val_loss: 0.9792 - val_accuracy: 0.5800\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9174 - accuracy: 0.5947 - val_loss: 1.0150 - val_accuracy: 0.5425\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9211 - accuracy: 0.5938 - val_loss: 0.9666 - val_accuracy: 0.6125\n",
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.5930 - val_loss: 0.9843 - val_accuracy: 0.5550\n",
      "Epoch 401/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9224 - accuracy: 0.5963 - val_loss: 0.9658 - val_accuracy: 0.5925\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9199 - accuracy: 0.5938 - val_loss: 0.9736 - val_accuracy: 0.5825\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9226 - accuracy: 0.5855 - val_loss: 0.9864 - val_accuracy: 0.5625\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9221 - accuracy: 0.5905 - val_loss: 0.9677 - val_accuracy: 0.5900\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9142 - accuracy: 0.5980 - val_loss: 0.9803 - val_accuracy: 0.5700\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9287 - accuracy: 0.5938 - val_loss: 0.9792 - val_accuracy: 0.5950\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.6055 - val_loss: 1.0148 - val_accuracy: 0.5725\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9168 - accuracy: 0.5963 - val_loss: 0.9833 - val_accuracy: 0.5800\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9144 - accuracy: 0.6138 - val_loss: 0.9750 - val_accuracy: 0.6025\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9102 - accuracy: 0.5980 - val_loss: 0.9808 - val_accuracy: 0.5875\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9193 - accuracy: 0.5997 - val_loss: 0.9945 - val_accuracy: 0.5750\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9208 - accuracy: 0.5938 - val_loss: 1.0385 - val_accuracy: 0.5275\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9178 - accuracy: 0.6063 - val_loss: 0.9907 - val_accuracy: 0.5725\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9208 - accuracy: 0.6038 - val_loss: 0.9771 - val_accuracy: 0.5850\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9104 - accuracy: 0.6055 - val_loss: 0.9861 - val_accuracy: 0.5675\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9199 - accuracy: 0.5830 - val_loss: 0.9879 - val_accuracy: 0.5850\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9120 - accuracy: 0.5922 - val_loss: 0.9914 - val_accuracy: 0.5700\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9083 - accuracy: 0.6072 - val_loss: 1.0003 - val_accuracy: 0.5750\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9233 - accuracy: 0.5997 - val_loss: 1.0110 - val_accuracy: 0.5600\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9209 - accuracy: 0.5963 - val_loss: 0.9987 - val_accuracy: 0.5650\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9155 - accuracy: 0.6055 - val_loss: 0.9985 - val_accuracy: 0.6050\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9205 - accuracy: 0.5855 - val_loss: 1.0139 - val_accuracy: 0.5525\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.5963 - val_loss: 0.9832 - val_accuracy: 0.5800\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.6088 - val_loss: 0.9867 - val_accuracy: 0.5825\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9129 - accuracy: 0.6013 - val_loss: 1.0019 - val_accuracy: 0.5625\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9241 - accuracy: 0.5980 - val_loss: 1.0153 - val_accuracy: 0.5525\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.5997 - val_loss: 0.9793 - val_accuracy: 0.6025\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9135 - accuracy: 0.5980 - val_loss: 0.9698 - val_accuracy: 0.6100\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.6013 - val_loss: 0.9842 - val_accuracy: 0.6075\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.6022 - val_loss: 1.0023 - val_accuracy: 0.5600\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9097 - accuracy: 0.6105 - val_loss: 0.9861 - val_accuracy: 0.5700\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9082 - accuracy: 0.6105 - val_loss: 0.9873 - val_accuracy: 0.5925\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9083 - accuracy: 0.5988 - val_loss: 1.0003 - val_accuracy: 0.5725\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9094 - accuracy: 0.6038 - val_loss: 1.0046 - val_accuracy: 0.5725\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.5938 - val_loss: 0.9862 - val_accuracy: 0.5600\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9229 - accuracy: 0.5972 - val_loss: 0.9937 - val_accuracy: 0.5525\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.5922 - val_loss: 1.0102 - val_accuracy: 0.5475\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9185 - accuracy: 0.6113 - val_loss: 1.0002 - val_accuracy: 0.5425\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9143 - accuracy: 0.5980 - val_loss: 0.9725 - val_accuracy: 0.6075\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6022 - val_loss: 1.0389 - val_accuracy: 0.5225\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9153 - accuracy: 0.6030 - val_loss: 0.9979 - val_accuracy: 0.5550\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.5997 - val_loss: 0.9853 - val_accuracy: 0.5700\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9120 - accuracy: 0.6055 - val_loss: 0.9812 - val_accuracy: 0.5875\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.6055 - val_loss: 1.0092 - val_accuracy: 0.5725\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9109 - accuracy: 0.5997 - val_loss: 1.0000 - val_accuracy: 0.5525\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9165 - accuracy: 0.5938 - val_loss: 1.0122 - val_accuracy: 0.5750\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.5930 - val_loss: 1.0149 - val_accuracy: 0.5500\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9108 - accuracy: 0.6005 - val_loss: 0.9906 - val_accuracy: 0.5850\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9104 - accuracy: 0.6055 - val_loss: 0.9816 - val_accuracy: 0.6000\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9131 - accuracy: 0.5997 - val_loss: 0.9919 - val_accuracy: 0.5725\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9104 - accuracy: 0.6022 - val_loss: 0.9910 - val_accuracy: 0.5725\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9085 - accuracy: 0.6088 - val_loss: 0.9786 - val_accuracy: 0.5900\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.6022 - val_loss: 0.9862 - val_accuracy: 0.5700\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9117 - accuracy: 0.6013 - val_loss: 0.9727 - val_accuracy: 0.6050\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.6047 - val_loss: 0.9972 - val_accuracy: 0.5675\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9130 - accuracy: 0.5922 - val_loss: 0.9759 - val_accuracy: 0.5950\n",
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.5888 - val_loss: 0.9913 - val_accuracy: 0.5725\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9067 - accuracy: 0.6163 - val_loss: 0.9785 - val_accuracy: 0.5950\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9151 - accuracy: 0.5888 - val_loss: 0.9760 - val_accuracy: 0.5950\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9108 - accuracy: 0.5988 - val_loss: 0.9836 - val_accuracy: 0.5775\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9068 - accuracy: 0.6013 - val_loss: 1.0112 - val_accuracy: 0.5700\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9129 - accuracy: 0.6022 - val_loss: 0.9987 - val_accuracy: 0.5600\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.5988 - val_loss: 1.0092 - val_accuracy: 0.5625\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.6030 - val_loss: 1.0376 - val_accuracy: 0.5725\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9164 - accuracy: 0.5905 - val_loss: 0.9999 - val_accuracy: 0.5700\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.5855 - val_loss: 1.0162 - val_accuracy: 0.5600\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9264 - accuracy: 0.6047 - val_loss: 0.9873 - val_accuracy: 0.6000\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.5963 - val_loss: 0.9983 - val_accuracy: 0.5825\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.5980 - val_loss: 0.9926 - val_accuracy: 0.5850\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9209 - accuracy: 0.5963 - val_loss: 0.9957 - val_accuracy: 0.5725\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.5938 - val_loss: 1.0013 - val_accuracy: 0.5750\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9105 - accuracy: 0.6022 - val_loss: 0.9760 - val_accuracy: 0.6000\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9070 - accuracy: 0.6122 - val_loss: 1.0306 - val_accuracy: 0.5400\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.6022 - val_loss: 1.0035 - val_accuracy: 0.5625\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9088 - accuracy: 0.5963 - val_loss: 1.0152 - val_accuracy: 0.5600\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.6163 - val_loss: 1.0103 - val_accuracy: 0.5525\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9050 - accuracy: 0.5922 - val_loss: 1.0088 - val_accuracy: 0.5800\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6013 - val_loss: 1.0030 - val_accuracy: 0.5800\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9130 - accuracy: 0.5988 - val_loss: 1.0006 - val_accuracy: 0.5650\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9171 - accuracy: 0.6030 - val_loss: 1.0123 - val_accuracy: 0.5675\n",
      "Epoch 481/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9099 - accuracy: 0.6047 - val_loss: 0.9927 - val_accuracy: 0.5875\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9015 - accuracy: 0.6030 - val_loss: 1.0281 - val_accuracy: 0.5875\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 0.6055 - val_loss: 0.9997 - val_accuracy: 0.5875\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9140 - accuracy: 0.6030 - val_loss: 0.9868 - val_accuracy: 0.5775\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.6055 - val_loss: 1.0009 - val_accuracy: 0.5725\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9108 - accuracy: 0.5930 - val_loss: 0.9844 - val_accuracy: 0.5800\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9038 - accuracy: 0.6047 - val_loss: 1.0122 - val_accuracy: 0.5750\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9194 - accuracy: 0.5922 - val_loss: 0.9825 - val_accuracy: 0.5775\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6080 - val_loss: 0.9971 - val_accuracy: 0.6000\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9038 - accuracy: 0.6030 - val_loss: 0.9804 - val_accuracy: 0.5975\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.5938 - val_loss: 0.9980 - val_accuracy: 0.6075\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9163 - accuracy: 0.6013 - val_loss: 1.0120 - val_accuracy: 0.5575\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9108 - accuracy: 0.6105 - val_loss: 0.9836 - val_accuracy: 0.5800\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9093 - accuracy: 0.6030 - val_loss: 1.0237 - val_accuracy: 0.5625\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.5972 - val_loss: 1.0134 - val_accuracy: 0.5650\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9157 - accuracy: 0.6013 - val_loss: 1.0097 - val_accuracy: 0.5550\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9080 - accuracy: 0.6163 - val_loss: 1.0126 - val_accuracy: 0.5600\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9119 - accuracy: 0.5880 - val_loss: 1.0146 - val_accuracy: 0.5525\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9048 - accuracy: 0.6080 - val_loss: 1.0045 - val_accuracy: 0.5625\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.6063 - val_loss: 1.0001 - val_accuracy: 0.5900\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9143 - accuracy: 0.5847 - val_loss: 0.9926 - val_accuracy: 0.5575\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9051 - accuracy: 0.6097 - val_loss: 1.0007 - val_accuracy: 0.5800\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9106 - accuracy: 0.5955 - val_loss: 1.0769 - val_accuracy: 0.5200\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9133 - accuracy: 0.6047 - val_loss: 0.9957 - val_accuracy: 0.5850\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9050 - accuracy: 0.5988 - val_loss: 0.9965 - val_accuracy: 0.5650\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8998 - accuracy: 0.6022 - val_loss: 1.0211 - val_accuracy: 0.5750\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6130 - val_loss: 1.0295 - val_accuracy: 0.5325\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9102 - accuracy: 0.5980 - val_loss: 0.9875 - val_accuracy: 0.5750\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.6063 - val_loss: 0.9854 - val_accuracy: 0.6125\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9239 - accuracy: 0.6105 - val_loss: 0.9928 - val_accuracy: 0.5775\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9059 - accuracy: 0.6038 - val_loss: 1.0030 - val_accuracy: 0.5500\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.6055 - val_loss: 0.9799 - val_accuracy: 0.5875\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6013 - val_loss: 0.9894 - val_accuracy: 0.5975\n",
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9009 - accuracy: 0.6147 - val_loss: 1.0094 - val_accuracy: 0.5550\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8959 - accuracy: 0.6080 - val_loss: 0.9927 - val_accuracy: 0.5875\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6063 - val_loss: 1.0080 - val_accuracy: 0.5650\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.5947 - val_loss: 0.9886 - val_accuracy: 0.5850\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9074 - accuracy: 0.6013 - val_loss: 1.0220 - val_accuracy: 0.5825\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8979 - accuracy: 0.6138 - val_loss: 1.0064 - val_accuracy: 0.5875\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.6072 - val_loss: 1.0204 - val_accuracy: 0.5525\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.6122 - val_loss: 1.0307 - val_accuracy: 0.5400\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9043 - accuracy: 0.6030 - val_loss: 1.0037 - val_accuracy: 0.5525\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9023 - accuracy: 0.6122 - val_loss: 1.0421 - val_accuracy: 0.5675\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9151 - accuracy: 0.5888 - val_loss: 0.9847 - val_accuracy: 0.5975\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.6205 - val_loss: 0.9806 - val_accuracy: 0.6025\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.6138 - val_loss: 1.0086 - val_accuracy: 0.5900\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.5922 - val_loss: 1.0230 - val_accuracy: 0.5675\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.6005 - val_loss: 0.9883 - val_accuracy: 0.5800\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9006 - accuracy: 0.5972 - val_loss: 1.0038 - val_accuracy: 0.5900\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9162 - accuracy: 0.5980 - val_loss: 0.9863 - val_accuracy: 0.5725\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8938 - accuracy: 0.6047 - val_loss: 0.9960 - val_accuracy: 0.5750\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9194 - accuracy: 0.5988 - val_loss: 0.9996 - val_accuracy: 0.5800\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9049 - accuracy: 0.6155 - val_loss: 0.9791 - val_accuracy: 0.6125\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9072 - accuracy: 0.6105 - val_loss: 0.9773 - val_accuracy: 0.5875\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8994 - accuracy: 0.6055 - val_loss: 0.9762 - val_accuracy: 0.5775\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.6088 - val_loss: 1.0062 - val_accuracy: 0.5425\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8959 - accuracy: 0.6188 - val_loss: 1.0040 - val_accuracy: 0.5775\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9039 - accuracy: 0.6113 - val_loss: 1.0083 - val_accuracy: 0.5575\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.6047 - val_loss: 1.0318 - val_accuracy: 0.5525\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9073 - accuracy: 0.5980 - val_loss: 1.0034 - val_accuracy: 0.5625\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8962 - accuracy: 0.6088 - val_loss: 1.0477 - val_accuracy: 0.5575\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9015 - accuracy: 0.6097 - val_loss: 1.0163 - val_accuracy: 0.5525\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.6080 - val_loss: 0.9827 - val_accuracy: 0.5950\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9050 - accuracy: 0.6022 - val_loss: 0.9927 - val_accuracy: 0.5725\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.5963 - val_loss: 1.0261 - val_accuracy: 0.5325\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9109 - accuracy: 0.5972 - val_loss: 1.0032 - val_accuracy: 0.5575\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.6063 - val_loss: 1.0372 - val_accuracy: 0.5425\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9036 - accuracy: 0.6080 - val_loss: 1.0415 - val_accuracy: 0.5350\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9059 - accuracy: 0.6055 - val_loss: 1.0470 - val_accuracy: 0.5250\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9010 - accuracy: 0.5988 - val_loss: 0.9907 - val_accuracy: 0.5700\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.6047 - val_loss: 0.9892 - val_accuracy: 0.5925\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8936 - accuracy: 0.6122 - val_loss: 1.0105 - val_accuracy: 0.5450\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9033 - accuracy: 0.6072 - val_loss: 0.9899 - val_accuracy: 0.5800\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8983 - accuracy: 0.5947 - val_loss: 1.0178 - val_accuracy: 0.5450\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.6063 - val_loss: 0.9946 - val_accuracy: 0.5975\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6155 - val_loss: 1.0058 - val_accuracy: 0.5575\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 0.6122 - val_loss: 1.0111 - val_accuracy: 0.5675\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9073 - accuracy: 0.6038 - val_loss: 1.0215 - val_accuracy: 0.5525\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9023 - accuracy: 0.5972 - val_loss: 1.0488 - val_accuracy: 0.5550\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9115 - accuracy: 0.5955 - val_loss: 0.9888 - val_accuracy: 0.5900\n",
      "Epoch 561/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.6155 - val_loss: 1.0252 - val_accuracy: 0.5600\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9015 - accuracy: 0.6072 - val_loss: 1.0049 - val_accuracy: 0.5700\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.6030 - val_loss: 1.0271 - val_accuracy: 0.5425\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.5947 - val_loss: 0.9961 - val_accuracy: 0.5800\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9072 - accuracy: 0.6055 - val_loss: 0.9891 - val_accuracy: 0.5700\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8967 - accuracy: 0.6038 - val_loss: 1.0327 - val_accuracy: 0.5675\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9003 - accuracy: 0.5988 - val_loss: 1.0161 - val_accuracy: 0.6100\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.6055 - val_loss: 0.9816 - val_accuracy: 0.6150\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9032 - accuracy: 0.6080 - val_loss: 1.0075 - val_accuracy: 0.5800\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8918 - accuracy: 0.6138 - val_loss: 1.0098 - val_accuracy: 0.5700\n",
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9059 - accuracy: 0.5930 - val_loss: 0.9975 - val_accuracy: 0.5650\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9022 - accuracy: 0.6138 - val_loss: 0.9836 - val_accuracy: 0.6050\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6030 - val_loss: 1.0009 - val_accuracy: 0.5500\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8997 - accuracy: 0.6013 - val_loss: 1.0013 - val_accuracy: 0.5450\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6122 - val_loss: 0.9968 - val_accuracy: 0.5725\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8995 - accuracy: 0.6080 - val_loss: 0.9882 - val_accuracy: 0.6025\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9041 - accuracy: 0.6063 - val_loss: 1.0095 - val_accuracy: 0.5650\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8945 - accuracy: 0.6264 - val_loss: 1.0314 - val_accuracy: 0.5500\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.6088 - val_loss: 1.0003 - val_accuracy: 0.5475\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6047 - val_loss: 1.0069 - val_accuracy: 0.5650\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.6147 - val_loss: 1.0336 - val_accuracy: 0.5600\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9023 - accuracy: 0.5938 - val_loss: 1.0069 - val_accuracy: 0.5775\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9012 - accuracy: 0.6080 - val_loss: 1.0278 - val_accuracy: 0.5350\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9035 - accuracy: 0.6030 - val_loss: 1.0166 - val_accuracy: 0.5425\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9053 - accuracy: 0.6055 - val_loss: 0.9952 - val_accuracy: 0.5900\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9010 - accuracy: 0.6097 - val_loss: 0.9940 - val_accuracy: 0.5650\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6163 - val_loss: 1.0105 - val_accuracy: 0.5525\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9040 - accuracy: 0.6022 - val_loss: 1.0251 - val_accuracy: 0.5550\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.6122 - val_loss: 0.9778 - val_accuracy: 0.5950\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9021 - accuracy: 0.5988 - val_loss: 1.0191 - val_accuracy: 0.5425\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.6097 - val_loss: 0.9849 - val_accuracy: 0.6000\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9011 - accuracy: 0.6105 - val_loss: 0.9946 - val_accuracy: 0.5675\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9051 - accuracy: 0.6080 - val_loss: 0.9997 - val_accuracy: 0.5750\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.6088 - val_loss: 0.9900 - val_accuracy: 0.5925\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8907 - accuracy: 0.6088 - val_loss: 1.0151 - val_accuracy: 0.5375\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.6080 - val_loss: 1.0256 - val_accuracy: 0.5525\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9037 - accuracy: 0.6055 - val_loss: 0.9993 - val_accuracy: 0.5550\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9009 - accuracy: 0.6030 - val_loss: 1.0002 - val_accuracy: 0.5875\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8917 - accuracy: 0.6097 - val_loss: 1.0465 - val_accuracy: 0.5625\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.6013 - val_loss: 0.9985 - val_accuracy: 0.5775\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9027 - accuracy: 0.6188 - val_loss: 1.0085 - val_accuracy: 0.5525\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.6080 - val_loss: 1.0246 - val_accuracy: 0.5600\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.6138 - val_loss: 0.9884 - val_accuracy: 0.5600\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8933 - accuracy: 0.6022 - val_loss: 1.0269 - val_accuracy: 0.5325\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.6030 - val_loss: 1.0070 - val_accuracy: 0.5375\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9038 - accuracy: 0.6030 - val_loss: 1.0142 - val_accuracy: 0.5550\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9229 - accuracy: 0.5905 - val_loss: 1.0030 - val_accuracy: 0.5550\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8993 - accuracy: 0.5988 - val_loss: 0.9850 - val_accuracy: 0.5575\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9008 - accuracy: 0.6047 - val_loss: 0.9900 - val_accuracy: 0.5850\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.5997 - val_loss: 1.0150 - val_accuracy: 0.5600\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8987 - accuracy: 0.6063 - val_loss: 1.0145 - val_accuracy: 0.5700\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8941 - accuracy: 0.6022 - val_loss: 1.0106 - val_accuracy: 0.5750\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9024 - accuracy: 0.6130 - val_loss: 1.0342 - val_accuracy: 0.5500\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8909 - accuracy: 0.6113 - val_loss: 0.9861 - val_accuracy: 0.5650\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8975 - accuracy: 0.6030 - val_loss: 1.0278 - val_accuracy: 0.5650\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9199 - accuracy: 0.5947 - val_loss: 1.0099 - val_accuracy: 0.5575\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8960 - accuracy: 0.6080 - val_loss: 0.9930 - val_accuracy: 0.5675\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9076 - accuracy: 0.6038 - val_loss: 1.0024 - val_accuracy: 0.5425\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8907 - accuracy: 0.6155 - val_loss: 1.0403 - val_accuracy: 0.5400\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.6088 - val_loss: 0.9867 - val_accuracy: 0.5525\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9010 - accuracy: 0.6063 - val_loss: 1.0185 - val_accuracy: 0.5375\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9000 - accuracy: 0.6113 - val_loss: 1.0128 - val_accuracy: 0.5450\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6055 - val_loss: 1.0553 - val_accuracy: 0.5350\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9009 - accuracy: 0.6088 - val_loss: 1.0251 - val_accuracy: 0.5550\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8971 - accuracy: 0.6122 - val_loss: 1.0381 - val_accuracy: 0.5400\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.6072 - val_loss: 0.9954 - val_accuracy: 0.5625\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9041 - accuracy: 0.6005 - val_loss: 0.9930 - val_accuracy: 0.5875\n",
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.6113 - val_loss: 1.0131 - val_accuracy: 0.5450\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8953 - accuracy: 0.6138 - val_loss: 1.0026 - val_accuracy: 0.5600\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.6063 - val_loss: 1.0190 - val_accuracy: 0.5250\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8930 - accuracy: 0.6088 - val_loss: 1.0015 - val_accuracy: 0.5700\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8854 - accuracy: 0.6113 - val_loss: 1.0137 - val_accuracy: 0.5550\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8913 - accuracy: 0.6105 - val_loss: 0.9870 - val_accuracy: 0.5875\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.5922 - val_loss: 1.0185 - val_accuracy: 0.5500\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9072 - accuracy: 0.6022 - val_loss: 0.9972 - val_accuracy: 0.5775\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8914 - accuracy: 0.6180 - val_loss: 1.0168 - val_accuracy: 0.5475\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.6155 - val_loss: 1.0213 - val_accuracy: 0.5550\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8932 - accuracy: 0.6130 - val_loss: 1.0279 - val_accuracy: 0.5325\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8892 - accuracy: 0.6138 - val_loss: 1.0096 - val_accuracy: 0.5625\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.6097 - val_loss: 1.0110 - val_accuracy: 0.5600\n",
      "Epoch 641/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9076 - accuracy: 0.6022 - val_loss: 1.0295 - val_accuracy: 0.5250\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8881 - accuracy: 0.6155 - val_loss: 1.0353 - val_accuracy: 0.5500\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8940 - accuracy: 0.6055 - val_loss: 1.0211 - val_accuracy: 0.5500\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.6147 - val_loss: 1.0159 - val_accuracy: 0.5575\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.6147 - val_loss: 1.0149 - val_accuracy: 0.5425\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8943 - accuracy: 0.6147 - val_loss: 1.0485 - val_accuracy: 0.5400\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8970 - accuracy: 0.6055 - val_loss: 1.0212 - val_accuracy: 0.5525\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8914 - accuracy: 0.6155 - val_loss: 1.0033 - val_accuracy: 0.5650\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8923 - accuracy: 0.6088 - val_loss: 1.0105 - val_accuracy: 0.5425\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9039 - accuracy: 0.6063 - val_loss: 0.9765 - val_accuracy: 0.5775\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.5997 - val_loss: 1.0038 - val_accuracy: 0.5550\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8878 - accuracy: 0.6197 - val_loss: 1.0245 - val_accuracy: 0.5350\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8951 - accuracy: 0.5997 - val_loss: 1.0238 - val_accuracy: 0.5375\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6172 - val_loss: 0.9974 - val_accuracy: 0.5575\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.6147 - val_loss: 1.0264 - val_accuracy: 0.5400\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8916 - accuracy: 0.6155 - val_loss: 1.0089 - val_accuracy: 0.5825\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8957 - accuracy: 0.6163 - val_loss: 1.0433 - val_accuracy: 0.5650\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6022 - val_loss: 1.0149 - val_accuracy: 0.5475\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8964 - accuracy: 0.6097 - val_loss: 1.0070 - val_accuracy: 0.5550\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8884 - accuracy: 0.6172 - val_loss: 1.0227 - val_accuracy: 0.5600\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8974 - accuracy: 0.6180 - val_loss: 1.0143 - val_accuracy: 0.5400\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8905 - accuracy: 0.6063 - val_loss: 1.0109 - val_accuracy: 0.5625\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.6222 - val_loss: 1.0117 - val_accuracy: 0.5850\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8925 - accuracy: 0.6088 - val_loss: 1.0115 - val_accuracy: 0.5575\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8882 - accuracy: 0.6063 - val_loss: 1.0305 - val_accuracy: 0.5600\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8902 - accuracy: 0.6063 - val_loss: 1.0485 - val_accuracy: 0.5550\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.6130 - val_loss: 1.0269 - val_accuracy: 0.5450\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8902 - accuracy: 0.6113 - val_loss: 1.0119 - val_accuracy: 0.5500\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.5972 - val_loss: 0.9925 - val_accuracy: 0.5800\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8879 - accuracy: 0.6155 - val_loss: 1.0202 - val_accuracy: 0.5325\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6013 - val_loss: 1.0457 - val_accuracy: 0.5750\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9034 - accuracy: 0.6072 - val_loss: 1.0078 - val_accuracy: 0.5800\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.6072 - val_loss: 0.9873 - val_accuracy: 0.5875\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.6130 - val_loss: 1.0068 - val_accuracy: 0.5450\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8806 - accuracy: 0.6205 - val_loss: 0.9981 - val_accuracy: 0.5650\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.6130 - val_loss: 1.0072 - val_accuracy: 0.5500\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8992 - accuracy: 0.6088 - val_loss: 1.0038 - val_accuracy: 0.5600\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6030 - val_loss: 1.0250 - val_accuracy: 0.5475\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8889 - accuracy: 0.6113 - val_loss: 1.0411 - val_accuracy: 0.5600\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6205 - val_loss: 1.0176 - val_accuracy: 0.5525\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.6055 - val_loss: 1.0352 - val_accuracy: 0.5325\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6038 - val_loss: 1.0370 - val_accuracy: 0.5475\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6113 - val_loss: 1.0193 - val_accuracy: 0.5425\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8897 - accuracy: 0.6113 - val_loss: 1.0242 - val_accuracy: 0.5525\n",
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8881 - accuracy: 0.6113 - val_loss: 1.0158 - val_accuracy: 0.5475\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.6205 - val_loss: 1.0042 - val_accuracy: 0.5900\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8906 - accuracy: 0.6147 - val_loss: 1.0063 - val_accuracy: 0.5525\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8866 - accuracy: 0.6122 - val_loss: 1.0059 - val_accuracy: 0.5650\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8917 - accuracy: 0.6097 - val_loss: 1.0414 - val_accuracy: 0.5650\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8932 - accuracy: 0.6105 - val_loss: 1.0234 - val_accuracy: 0.5525\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8860 - accuracy: 0.6230 - val_loss: 0.9989 - val_accuracy: 0.5925\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8985 - accuracy: 0.6230 - val_loss: 1.0174 - val_accuracy: 0.5650\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8884 - accuracy: 0.6097 - val_loss: 1.0351 - val_accuracy: 0.5525\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.6222 - val_loss: 1.0100 - val_accuracy: 0.5725\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.6072 - val_loss: 1.0471 - val_accuracy: 0.5400\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8937 - accuracy: 0.6172 - val_loss: 1.0510 - val_accuracy: 0.5300\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8945 - accuracy: 0.5997 - val_loss: 1.0067 - val_accuracy: 0.5625\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.6088 - val_loss: 1.0111 - val_accuracy: 0.5575\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6047 - val_loss: 1.0182 - val_accuracy: 0.5600\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.6072 - val_loss: 1.0254 - val_accuracy: 0.5275\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8836 - accuracy: 0.6197 - val_loss: 1.0074 - val_accuracy: 0.5625\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8882 - accuracy: 0.6088 - val_loss: 1.0173 - val_accuracy: 0.5675\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8884 - accuracy: 0.5997 - val_loss: 1.0195 - val_accuracy: 0.5500\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8886 - accuracy: 0.6113 - val_loss: 1.0114 - val_accuracy: 0.5550\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8932 - accuracy: 0.5997 - val_loss: 0.9989 - val_accuracy: 0.5525\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8948 - accuracy: 0.6080 - val_loss: 0.9970 - val_accuracy: 0.5650\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8900 - accuracy: 0.6180 - val_loss: 1.0103 - val_accuracy: 0.5675\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.6097 - val_loss: 0.9926 - val_accuracy: 0.5725\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8852 - accuracy: 0.6122 - val_loss: 1.0012 - val_accuracy: 0.5525\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8840 - accuracy: 0.6130 - val_loss: 0.9944 - val_accuracy: 0.5775\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.6113 - val_loss: 0.9892 - val_accuracy: 0.5650\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.6080 - val_loss: 0.9921 - val_accuracy: 0.5625\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9006 - accuracy: 0.5963 - val_loss: 1.0107 - val_accuracy: 0.5500\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8842 - accuracy: 0.6163 - val_loss: 1.0333 - val_accuracy: 0.5475\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.6047 - val_loss: 1.0158 - val_accuracy: 0.5675\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8891 - accuracy: 0.6138 - val_loss: 1.0346 - val_accuracy: 0.5375\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8946 - accuracy: 0.6030 - val_loss: 1.0174 - val_accuracy: 0.5800\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.6072 - val_loss: 1.0126 - val_accuracy: 0.5525\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8814 - accuracy: 0.6188 - val_loss: 1.0059 - val_accuracy: 0.5675\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8770 - accuracy: 0.6105 - val_loss: 1.0208 - val_accuracy: 0.5600\n",
      "Epoch 721/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6047 - val_loss: 1.0207 - val_accuracy: 0.5525\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.6147 - val_loss: 1.0039 - val_accuracy: 0.5650\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8830 - accuracy: 0.6172 - val_loss: 0.9955 - val_accuracy: 0.5950\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8966 - accuracy: 0.6163 - val_loss: 1.0331 - val_accuracy: 0.5375\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8958 - accuracy: 0.6063 - val_loss: 0.9942 - val_accuracy: 0.5800\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8845 - accuracy: 0.6222 - val_loss: 1.0288 - val_accuracy: 0.5425\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6130 - val_loss: 0.9910 - val_accuracy: 0.5700\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8775 - accuracy: 0.6122 - val_loss: 1.0306 - val_accuracy: 0.5600\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.6105 - val_loss: 1.0064 - val_accuracy: 0.5425\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8814 - accuracy: 0.6155 - val_loss: 1.0122 - val_accuracy: 0.5575\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.6005 - val_loss: 1.0307 - val_accuracy: 0.5250\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8855 - accuracy: 0.6163 - val_loss: 0.9855 - val_accuracy: 0.5750\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8792 - accuracy: 0.6188 - val_loss: 1.0107 - val_accuracy: 0.6000\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8882 - accuracy: 0.6113 - val_loss: 1.0118 - val_accuracy: 0.5350\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.6122 - val_loss: 1.0064 - val_accuracy: 0.5750\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6147 - val_loss: 1.0147 - val_accuracy: 0.5650\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8837 - accuracy: 0.6105 - val_loss: 1.0089 - val_accuracy: 0.5450\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8892 - accuracy: 0.6047 - val_loss: 1.0097 - val_accuracy: 0.5525\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.6147 - val_loss: 1.0084 - val_accuracy: 0.5475\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8853 - accuracy: 0.6122 - val_loss: 0.9909 - val_accuracy: 0.5750\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8887 - accuracy: 0.6047 - val_loss: 1.0264 - val_accuracy: 0.5325\n",
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8943 - accuracy: 0.6105 - val_loss: 1.0108 - val_accuracy: 0.5700\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.6022 - val_loss: 1.0035 - val_accuracy: 0.5550\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8892 - accuracy: 0.6147 - val_loss: 1.0600 - val_accuracy: 0.5275\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8842 - accuracy: 0.6080 - val_loss: 1.0081 - val_accuracy: 0.5500\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8834 - accuracy: 0.6113 - val_loss: 1.0049 - val_accuracy: 0.5725\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8839 - accuracy: 0.6247 - val_loss: 1.0227 - val_accuracy: 0.5200\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.6138 - val_loss: 1.0021 - val_accuracy: 0.5775\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.6172 - val_loss: 1.0334 - val_accuracy: 0.5650\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8926 - accuracy: 0.6013 - val_loss: 1.0071 - val_accuracy: 0.5650\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8842 - accuracy: 0.6138 - val_loss: 0.9927 - val_accuracy: 0.5725\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.6138 - val_loss: 1.0403 - val_accuracy: 0.5250\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.6197 - val_loss: 0.9786 - val_accuracy: 0.5700\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8851 - accuracy: 0.6172 - val_loss: 0.9994 - val_accuracy: 0.5525\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8809 - accuracy: 0.6230 - val_loss: 1.0352 - val_accuracy: 0.5300\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8875 - accuracy: 0.6038 - val_loss: 1.0052 - val_accuracy: 0.5650\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.6080 - val_loss: 0.9987 - val_accuracy: 0.5475\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8896 - accuracy: 0.6080 - val_loss: 1.0082 - val_accuracy: 0.5425\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8909 - accuracy: 0.6188 - val_loss: 1.0226 - val_accuracy: 0.5700\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.6105 - val_loss: 1.0040 - val_accuracy: 0.5775\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.6163 - val_loss: 0.9848 - val_accuracy: 0.5525\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8851 - accuracy: 0.6080 - val_loss: 1.0430 - val_accuracy: 0.5550\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6155 - val_loss: 1.0298 - val_accuracy: 0.5450\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.6197 - val_loss: 0.9997 - val_accuracy: 0.5750\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6130 - val_loss: 0.9942 - val_accuracy: 0.5725\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8839 - accuracy: 0.6155 - val_loss: 1.0270 - val_accuracy: 0.5250\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8853 - accuracy: 0.6197 - val_loss: 1.0136 - val_accuracy: 0.5500\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8793 - accuracy: 0.6163 - val_loss: 1.0613 - val_accuracy: 0.5025\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8880 - accuracy: 0.6097 - val_loss: 1.0096 - val_accuracy: 0.5675\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8816 - accuracy: 0.6255 - val_loss: 0.9890 - val_accuracy: 0.5675\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8754 - accuracy: 0.6297 - val_loss: 1.0169 - val_accuracy: 0.5700\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8869 - accuracy: 0.6105 - val_loss: 0.9859 - val_accuracy: 0.6100\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8782 - accuracy: 0.6272 - val_loss: 1.0178 - val_accuracy: 0.5400\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8759 - accuracy: 0.6289 - val_loss: 1.0410 - val_accuracy: 0.5225\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8793 - accuracy: 0.6222 - val_loss: 0.9989 - val_accuracy: 0.5925\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8763 - accuracy: 0.6130 - val_loss: 1.0001 - val_accuracy: 0.5900\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8824 - accuracy: 0.6247 - val_loss: 0.9927 - val_accuracy: 0.5625\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8886 - accuracy: 0.6138 - val_loss: 1.0009 - val_accuracy: 0.5700\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8766 - accuracy: 0.6230 - val_loss: 0.9943 - val_accuracy: 0.5575\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8953 - accuracy: 0.6122 - val_loss: 0.9864 - val_accuracy: 0.5950\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8914 - accuracy: 0.6180 - val_loss: 1.0152 - val_accuracy: 0.5400\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8889 - accuracy: 0.6155 - val_loss: 1.0143 - val_accuracy: 0.5425\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6130 - val_loss: 1.0338 - val_accuracy: 0.5250\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8779 - accuracy: 0.6188 - val_loss: 1.0127 - val_accuracy: 0.5625\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8788 - accuracy: 0.6255 - val_loss: 1.0156 - val_accuracy: 0.5425\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8820 - accuracy: 0.6080 - val_loss: 0.9881 - val_accuracy: 0.5600\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8935 - accuracy: 0.6147 - val_loss: 0.9958 - val_accuracy: 0.5725\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8860 - accuracy: 0.6180 - val_loss: 1.0155 - val_accuracy: 0.5575\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6163 - val_loss: 1.0112 - val_accuracy: 0.5600\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6314 - val_loss: 0.9954 - val_accuracy: 0.5725\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8852 - accuracy: 0.6247 - val_loss: 1.0249 - val_accuracy: 0.5300\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8875 - accuracy: 0.6222 - val_loss: 1.0079 - val_accuracy: 0.5500\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8868 - accuracy: 0.6180 - val_loss: 1.0022 - val_accuracy: 0.5775\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8808 - accuracy: 0.6214 - val_loss: 0.9952 - val_accuracy: 0.5625\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6163 - val_loss: 1.0327 - val_accuracy: 0.5325\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8794 - accuracy: 0.6130 - val_loss: 0.9938 - val_accuracy: 0.5700\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8787 - accuracy: 0.6230 - val_loss: 1.0041 - val_accuracy: 0.5600\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8810 - accuracy: 0.6172 - val_loss: 1.0089 - val_accuracy: 0.5825\n",
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8803 - accuracy: 0.6214 - val_loss: 1.0008 - val_accuracy: 0.5675\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8788 - accuracy: 0.6205 - val_loss: 1.0021 - val_accuracy: 0.5575\n",
      "Epoch 801/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8842 - accuracy: 0.6105 - val_loss: 1.0492 - val_accuracy: 0.5425\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8820 - accuracy: 0.6188 - val_loss: 1.0347 - val_accuracy: 0.5575\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8861 - accuracy: 0.6080 - val_loss: 1.0181 - val_accuracy: 0.5675\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.6214 - val_loss: 0.9916 - val_accuracy: 0.5700\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8787 - accuracy: 0.6122 - val_loss: 1.0004 - val_accuracy: 0.5800\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8850 - accuracy: 0.6230 - val_loss: 0.9925 - val_accuracy: 0.5850\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.6205 - val_loss: 1.0036 - val_accuracy: 0.5500\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8773 - accuracy: 0.6180 - val_loss: 1.0278 - val_accuracy: 0.5725\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8802 - accuracy: 0.6230 - val_loss: 1.0139 - val_accuracy: 0.5650\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8848 - accuracy: 0.6264 - val_loss: 1.0036 - val_accuracy: 0.5475\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8889 - accuracy: 0.6255 - val_loss: 1.0070 - val_accuracy: 0.5250\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6255 - val_loss: 0.9909 - val_accuracy: 0.5750\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8808 - accuracy: 0.6155 - val_loss: 1.0007 - val_accuracy: 0.5700\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8937 - accuracy: 0.6163 - val_loss: 1.0127 - val_accuracy: 0.5675\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8771 - accuracy: 0.6222 - val_loss: 0.9999 - val_accuracy: 0.5725\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8867 - accuracy: 0.6205 - val_loss: 1.0087 - val_accuracy: 0.5400\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8682 - accuracy: 0.6214 - val_loss: 0.9832 - val_accuracy: 0.5700\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8784 - accuracy: 0.6289 - val_loss: 0.9926 - val_accuracy: 0.5500\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.6197 - val_loss: 1.0306 - val_accuracy: 0.5550\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8854 - accuracy: 0.6097 - val_loss: 0.9948 - val_accuracy: 0.5725\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8730 - accuracy: 0.6247 - val_loss: 1.0771 - val_accuracy: 0.5350\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8831 - accuracy: 0.6272 - val_loss: 1.0061 - val_accuracy: 0.5425\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8915 - accuracy: 0.6113 - val_loss: 1.0367 - val_accuracy: 0.5450\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8934 - accuracy: 0.6130 - val_loss: 0.9809 - val_accuracy: 0.5725\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8744 - accuracy: 0.6272 - val_loss: 1.0386 - val_accuracy: 0.5475\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8891 - accuracy: 0.6130 - val_loss: 0.9999 - val_accuracy: 0.5775\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8901 - accuracy: 0.6314 - val_loss: 1.0047 - val_accuracy: 0.5650\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8918 - accuracy: 0.6147 - val_loss: 1.0185 - val_accuracy: 0.5475\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8784 - accuracy: 0.6180 - val_loss: 0.9802 - val_accuracy: 0.5575\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8770 - accuracy: 0.6297 - val_loss: 1.0191 - val_accuracy: 0.5475\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.6230 - val_loss: 0.9792 - val_accuracy: 0.5625\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8707 - accuracy: 0.6355 - val_loss: 0.9972 - val_accuracy: 0.5550\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6155 - val_loss: 1.0185 - val_accuracy: 0.5400\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8780 - accuracy: 0.6205 - val_loss: 1.0190 - val_accuracy: 0.5725\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8875 - accuracy: 0.6230 - val_loss: 1.0001 - val_accuracy: 0.5675\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8766 - accuracy: 0.6230 - val_loss: 1.0057 - val_accuracy: 0.5475\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8727 - accuracy: 0.6214 - val_loss: 1.0152 - val_accuracy: 0.5550\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 0.6230 - val_loss: 1.0015 - val_accuracy: 0.5775\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8703 - accuracy: 0.6322 - val_loss: 1.0037 - val_accuracy: 0.5750\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8792 - accuracy: 0.6188 - val_loss: 1.0340 - val_accuracy: 0.5450\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8822 - accuracy: 0.6163 - val_loss: 0.9883 - val_accuracy: 0.5525\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.6372 - val_loss: 1.0189 - val_accuracy: 0.5525\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8792 - accuracy: 0.6247 - val_loss: 0.9780 - val_accuracy: 0.5600\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6297 - val_loss: 1.0065 - val_accuracy: 0.5575\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.6239 - val_loss: 1.0132 - val_accuracy: 0.5625\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8895 - accuracy: 0.6163 - val_loss: 1.0152 - val_accuracy: 0.5850\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8838 - accuracy: 0.6088 - val_loss: 1.0343 - val_accuracy: 0.5625\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8827 - accuracy: 0.6205 - val_loss: 1.0295 - val_accuracy: 0.5500\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8765 - accuracy: 0.6239 - val_loss: 1.0135 - val_accuracy: 0.5475\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8782 - accuracy: 0.6272 - val_loss: 1.0006 - val_accuracy: 0.5675\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.6188 - val_loss: 0.9886 - val_accuracy: 0.5700\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8904 - accuracy: 0.6247 - val_loss: 1.0028 - val_accuracy: 0.5600\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8700 - accuracy: 0.6339 - val_loss: 1.0034 - val_accuracy: 0.5875\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8669 - accuracy: 0.6264 - val_loss: 0.9905 - val_accuracy: 0.5675\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8716 - accuracy: 0.6280 - val_loss: 0.9910 - val_accuracy: 0.5625\n",
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8744 - accuracy: 0.6130 - val_loss: 1.0065 - val_accuracy: 0.5450\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.6105 - val_loss: 1.0139 - val_accuracy: 0.5300\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8801 - accuracy: 0.6255 - val_loss: 1.0254 - val_accuracy: 0.5350\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8828 - accuracy: 0.6147 - val_loss: 0.9889 - val_accuracy: 0.5850\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.6230 - val_loss: 1.0424 - val_accuracy: 0.5375\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8743 - accuracy: 0.6239 - val_loss: 1.0178 - val_accuracy: 0.5250\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8735 - accuracy: 0.6138 - val_loss: 0.9884 - val_accuracy: 0.5775\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6272 - val_loss: 0.9807 - val_accuracy: 0.5750\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6239 - val_loss: 1.0426 - val_accuracy: 0.5575\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.6222 - val_loss: 1.0132 - val_accuracy: 0.5675\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8769 - accuracy: 0.6163 - val_loss: 0.9998 - val_accuracy: 0.5625\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8736 - accuracy: 0.6230 - val_loss: 1.0018 - val_accuracy: 0.5725\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.6214 - val_loss: 1.0057 - val_accuracy: 0.5500\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8781 - accuracy: 0.6255 - val_loss: 1.0232 - val_accuracy: 0.5500\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8685 - accuracy: 0.6247 - val_loss: 1.0529 - val_accuracy: 0.5400\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8816 - accuracy: 0.6147 - val_loss: 1.0016 - val_accuracy: 0.5650\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.6239 - val_loss: 0.9903 - val_accuracy: 0.5725\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8718 - accuracy: 0.6347 - val_loss: 0.9985 - val_accuracy: 0.5500\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8770 - accuracy: 0.6197 - val_loss: 0.9937 - val_accuracy: 0.5650\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6230 - val_loss: 1.0038 - val_accuracy: 0.5650\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8775 - accuracy: 0.6138 - val_loss: 1.0044 - val_accuracy: 0.5675\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.5988 - val_loss: 0.9932 - val_accuracy: 0.5450\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.6188 - val_loss: 1.0137 - val_accuracy: 0.5650\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.6172 - val_loss: 0.9967 - val_accuracy: 0.5675\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8903 - accuracy: 0.6180 - val_loss: 0.9894 - val_accuracy: 0.5825\n",
      "Epoch 881/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8806 - accuracy: 0.6155 - val_loss: 1.0043 - val_accuracy: 0.5200\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8793 - accuracy: 0.6264 - val_loss: 1.0228 - val_accuracy: 0.5200\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8794 - accuracy: 0.6239 - val_loss: 1.0061 - val_accuracy: 0.5550\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8698 - accuracy: 0.6247 - val_loss: 1.0100 - val_accuracy: 0.5525\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8679 - accuracy: 0.6314 - val_loss: 0.9913 - val_accuracy: 0.5800\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8685 - accuracy: 0.6280 - val_loss: 1.0120 - val_accuracy: 0.5525\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8677 - accuracy: 0.6280 - val_loss: 1.0102 - val_accuracy: 0.5800\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8829 - accuracy: 0.6138 - val_loss: 1.0216 - val_accuracy: 0.5275\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8760 - accuracy: 0.6155 - val_loss: 1.0031 - val_accuracy: 0.5550\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8739 - accuracy: 0.6264 - val_loss: 0.9969 - val_accuracy: 0.5625\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8765 - accuracy: 0.6255 - val_loss: 0.9974 - val_accuracy: 0.5900\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8730 - accuracy: 0.6272 - val_loss: 1.0144 - val_accuracy: 0.5550\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.6113 - val_loss: 1.0179 - val_accuracy: 0.5450\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8824 - accuracy: 0.6214 - val_loss: 0.9956 - val_accuracy: 0.5750\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8708 - accuracy: 0.6239 - val_loss: 1.0282 - val_accuracy: 0.5400\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8869 - accuracy: 0.6147 - val_loss: 1.0258 - val_accuracy: 0.5800\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8683 - accuracy: 0.6364 - val_loss: 0.9861 - val_accuracy: 0.5750\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8762 - accuracy: 0.6239 - val_loss: 1.0008 - val_accuracy: 0.5775\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8719 - accuracy: 0.6272 - val_loss: 1.0011 - val_accuracy: 0.5900\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8728 - accuracy: 0.6280 - val_loss: 1.0035 - val_accuracy: 0.5750\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8776 - accuracy: 0.6172 - val_loss: 0.9961 - val_accuracy: 0.5750\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6205 - val_loss: 1.0071 - val_accuracy: 0.5425\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8742 - accuracy: 0.6272 - val_loss: 0.9988 - val_accuracy: 0.5775\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6147 - val_loss: 1.0118 - val_accuracy: 0.5875\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8667 - accuracy: 0.6289 - val_loss: 1.0000 - val_accuracy: 0.5700\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.6297 - val_loss: 1.0245 - val_accuracy: 0.5375\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.6222 - val_loss: 0.9927 - val_accuracy: 0.5750\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8683 - accuracy: 0.6272 - val_loss: 1.0348 - val_accuracy: 0.5325\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8736 - accuracy: 0.6214 - val_loss: 1.0346 - val_accuracy: 0.5775\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8745 - accuracy: 0.6247 - val_loss: 1.0147 - val_accuracy: 0.5800\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8740 - accuracy: 0.6255 - val_loss: 1.0180 - val_accuracy: 0.5275\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8901 - accuracy: 0.6147 - val_loss: 1.0236 - val_accuracy: 0.5750\n",
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8781 - accuracy: 0.6264 - val_loss: 1.0089 - val_accuracy: 0.5850\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8776 - accuracy: 0.6180 - val_loss: 1.0471 - val_accuracy: 0.5575\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8769 - accuracy: 0.6172 - val_loss: 1.0081 - val_accuracy: 0.5575\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8710 - accuracy: 0.6230 - val_loss: 1.0258 - val_accuracy: 0.5550\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8692 - accuracy: 0.6205 - val_loss: 0.9859 - val_accuracy: 0.5800\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6172 - val_loss: 1.0174 - val_accuracy: 0.5950\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.6222 - val_loss: 1.0197 - val_accuracy: 0.5400\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8704 - accuracy: 0.6239 - val_loss: 1.0220 - val_accuracy: 0.5250\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6339 - val_loss: 0.9970 - val_accuracy: 0.5850\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.6372 - val_loss: 0.9986 - val_accuracy: 0.5500\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8728 - accuracy: 0.6280 - val_loss: 1.0048 - val_accuracy: 0.5750\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8633 - accuracy: 0.6264 - val_loss: 1.0115 - val_accuracy: 0.5550\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8646 - accuracy: 0.6272 - val_loss: 1.0329 - val_accuracy: 0.5075\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8713 - accuracy: 0.6280 - val_loss: 1.0036 - val_accuracy: 0.5700\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8779 - accuracy: 0.6180 - val_loss: 0.9800 - val_accuracy: 0.6075\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8732 - accuracy: 0.6214 - val_loss: 1.0125 - val_accuracy: 0.5675\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8750 - accuracy: 0.6239 - val_loss: 1.0032 - val_accuracy: 0.5775\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6222 - val_loss: 1.0312 - val_accuracy: 0.5550\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8792 - accuracy: 0.6239 - val_loss: 1.0232 - val_accuracy: 0.5400\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8703 - accuracy: 0.6188 - val_loss: 1.0138 - val_accuracy: 0.5500\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.6289 - val_loss: 1.0098 - val_accuracy: 0.5625\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.6130 - val_loss: 1.0322 - val_accuracy: 0.5300\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8730 - accuracy: 0.6347 - val_loss: 1.0328 - val_accuracy: 0.5600\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6280 - val_loss: 1.0170 - val_accuracy: 0.5500\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.6239 - val_loss: 0.9858 - val_accuracy: 0.5700\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8678 - accuracy: 0.6163 - val_loss: 0.9973 - val_accuracy: 0.5700\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8775 - accuracy: 0.6239 - val_loss: 1.0112 - val_accuracy: 0.5600\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6147 - val_loss: 1.0463 - val_accuracy: 0.5375\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8661 - accuracy: 0.6222 - val_loss: 1.0109 - val_accuracy: 0.5725\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.6272 - val_loss: 1.0250 - val_accuracy: 0.5400\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6372 - val_loss: 1.0130 - val_accuracy: 0.5425\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8839 - accuracy: 0.6280 - val_loss: 1.0142 - val_accuracy: 0.5625\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8883 - accuracy: 0.6172 - val_loss: 1.0017 - val_accuracy: 0.5475\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6222 - val_loss: 1.0161 - val_accuracy: 0.5625\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8662 - accuracy: 0.6355 - val_loss: 1.0145 - val_accuracy: 0.5500\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8641 - accuracy: 0.6289 - val_loss: 1.0081 - val_accuracy: 0.5550\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8689 - accuracy: 0.6305 - val_loss: 0.9963 - val_accuracy: 0.5775\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8750 - accuracy: 0.6305 - val_loss: 0.9924 - val_accuracy: 0.5975\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.6163 - val_loss: 1.0062 - val_accuracy: 0.5575\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.6255 - val_loss: 1.0131 - val_accuracy: 0.5550\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8719 - accuracy: 0.6305 - val_loss: 1.0184 - val_accuracy: 0.5675\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8734 - accuracy: 0.6255 - val_loss: 1.0008 - val_accuracy: 0.5775\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.6330 - val_loss: 0.9976 - val_accuracy: 0.5800\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.6339 - val_loss: 1.0052 - val_accuracy: 0.5875\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6163 - val_loss: 1.0289 - val_accuracy: 0.5425\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8630 - accuracy: 0.6297 - val_loss: 1.0089 - val_accuracy: 0.5625\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.6364 - val_loss: 0.9865 - val_accuracy: 0.5925\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.6297 - val_loss: 0.9860 - val_accuracy: 0.5700\n",
      "Epoch 961/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8647 - accuracy: 0.6355 - val_loss: 1.0002 - val_accuracy: 0.5600\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6247 - val_loss: 0.9802 - val_accuracy: 0.5675\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.6297 - val_loss: 1.0133 - val_accuracy: 0.5675\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.6247 - val_loss: 0.9941 - val_accuracy: 0.5750\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8858 - accuracy: 0.6289 - val_loss: 1.0496 - val_accuracy: 0.5225\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.6339 - val_loss: 1.0320 - val_accuracy: 0.5650\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.6314 - val_loss: 1.0080 - val_accuracy: 0.5625\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.6264 - val_loss: 0.9898 - val_accuracy: 0.5725\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8648 - accuracy: 0.6314 - val_loss: 1.0393 - val_accuracy: 0.5275\n",
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8704 - accuracy: 0.6280 - val_loss: 1.0153 - val_accuracy: 0.5600\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.6247 - val_loss: 1.0036 - val_accuracy: 0.5850\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.6197 - val_loss: 1.0405 - val_accuracy: 0.5475\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8822 - accuracy: 0.6163 - val_loss: 0.9908 - val_accuracy: 0.5600\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8729 - accuracy: 0.6264 - val_loss: 0.9992 - val_accuracy: 0.5650\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.6272 - val_loss: 0.9947 - val_accuracy: 0.5850\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8906 - accuracy: 0.6113 - val_loss: 1.0028 - val_accuracy: 0.5625\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8739 - accuracy: 0.6088 - val_loss: 1.0406 - val_accuracy: 0.5325\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8638 - accuracy: 0.6430 - val_loss: 0.9986 - val_accuracy: 0.5650\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8620 - accuracy: 0.6230 - val_loss: 0.9933 - val_accuracy: 0.6025\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8793 - accuracy: 0.6314 - val_loss: 0.9920 - val_accuracy: 0.5575\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6230 - val_loss: 1.0078 - val_accuracy: 0.5650\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8893 - accuracy: 0.6122 - val_loss: 0.9796 - val_accuracy: 0.5825\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8724 - accuracy: 0.6188 - val_loss: 0.9844 - val_accuracy: 0.5700\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.6305 - val_loss: 1.0053 - val_accuracy: 0.5600\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8645 - accuracy: 0.6289 - val_loss: 0.9895 - val_accuracy: 0.5900\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8760 - accuracy: 0.6247 - val_loss: 0.9978 - val_accuracy: 0.5800\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8649 - accuracy: 0.6339 - val_loss: 1.0014 - val_accuracy: 0.5625\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8585 - accuracy: 0.6397 - val_loss: 0.9938 - val_accuracy: 0.5800\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.6222 - val_loss: 1.0076 - val_accuracy: 0.5475\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8742 - accuracy: 0.6239 - val_loss: 1.0328 - val_accuracy: 0.5325\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8827 - accuracy: 0.6272 - val_loss: 1.0400 - val_accuracy: 0.5325\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8633 - accuracy: 0.6389 - val_loss: 1.0122 - val_accuracy: 0.5875\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.6289 - val_loss: 1.0539 - val_accuracy: 0.5600\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8755 - accuracy: 0.6197 - val_loss: 0.9877 - val_accuracy: 0.5875\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8619 - accuracy: 0.6280 - val_loss: 0.9929 - val_accuracy: 0.5975\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.6322 - val_loss: 1.0303 - val_accuracy: 0.5275\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8751 - accuracy: 0.6264 - val_loss: 1.0133 - val_accuracy: 0.5575\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8617 - accuracy: 0.6264 - val_loss: 1.0040 - val_accuracy: 0.5700\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8735 - accuracy: 0.6155 - val_loss: 1.0057 - val_accuracy: 0.5750\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8647 - accuracy: 0.6264 - val_loss: 1.0282 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 990us/step\n"
     ]
    }
   ],
   "source": [
    "model_history=model.fit(x=X_train, y=y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1) # 배열에서 최댓값을 가지는 원소의 인덱스를 반환하는 함수\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14a98f89-20f9-4405-b369-f65cf6520bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 훈련 손실(training loss)과 검증 손실(validation loss) 추출\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "# 에포크(epoch) 범위 생성\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# 훈련 손실(training loss)과 검증 손실(validation loss) 시각화\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')  # 훈련 손실을 노란색(yellow)으로 플롯\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')  # 검증 손실을 빨간색(red)으로 플롯\n",
    "plt.title('Training and validation loss')  # 그래프 제목 설정\n",
    "plt.xlabel('Epochs')  # x축 레이블 설정\n",
    "plt.ylabel('Loss')  # y축 레이블 설정\n",
    "plt.legend()  # 범례(legend) 표시\n",
    "plt.show()  # 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e37248f0-70af-4b82-ab61-cc0f6055528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc =model_history.history['accuracy']\n",
    "val_acc =model_history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5939a4c9-2d04-4d8f-9016-749d8a95b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.60      0.82      0.69       169\n",
      "           3       0.56      0.39      0.46       170\n",
      "           4       0.38      0.45      0.41        40\n",
      "           5       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           0.56       400\n",
      "   macro avg       0.31      0.31      0.30       400\n",
      "weighted avg       0.53      0.56      0.53       400\n",
      "\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0   9   5   0   0]\n",
      " [  0   0 139  28   2   0]\n",
      " [  0   0  77  66  26   1]\n",
      " [  0   0   5  16  18   1]\n",
      " [  0   0   0   2   2   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.anaconda\\envs\\deep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\.anaconda\\envs\\deep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\.anaconda\\envs\\deep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the predicted values\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b508b64e-4051-4d0f-a269-f80438325c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0282 - accuracy: 0.5600\n",
      "테스트 데이터 손실: 1.0281765460968018\n",
      "테스트 데이터 정확도: 0.5600000023841858\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"테스트 데이터 손실:\", loss)\n",
    "print(\"테스트 데이터 정확도:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
